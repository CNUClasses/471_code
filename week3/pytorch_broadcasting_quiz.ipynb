{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5b8fbd",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch Broadcasting — Problem Set\n",
    "\n",
    "**Tip:** Broadcasting compares dimensions from right to left. Two dimensions are compatible if they are equal, or if either is 1. Pytorch will automatically add dimensions of size 1 to the left of the smaller dimensioned tensor if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5651de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Optional) If running locally, ensure PyTorch is installed.\n",
    "# !pip install torch -q\n",
    "\n",
    "import torch\n",
    "\n",
    "def shape(t): \n",
    "    return tuple(t.shape)\n",
    "\n",
    "torch.__version__ if 'torch' in globals() else 'PyTorch not installed in this environment.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb570ef0",
   "metadata": {},
   "source": [
    "\n",
    "## Applying to Neural Nets\n",
    "![](./dimensioned_nn.png)<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c8cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([32, 2])\n",
      "w.shape = torch.Size([2, 3])\n",
      "b.shape = torch.Size([1, 3])\n",
      "Y.shape = torch.Size([32, 3])\n",
      "Z.shape = torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "X=torch.ones(32,2)\n",
    "print(f'X.shape = {X.shape}')\n",
    "# print(X)\n",
    "\n",
    "w=torch.ones(2,3)*2\n",
    "print(f'w.shape = {w.shape}')\n",
    "# print(w)\n",
    "\n",
    "b=torch.ones(1,3)*3\n",
    "print(f'b.shape = {b.shape}')\n",
    "# print(b)\n",
    "\n",
    "#matrix multiply X and w\n",
    "Y=X@w\n",
    "print(f'Y.shape = {Y.shape}')\n",
    "# print(Y)\n",
    "\n",
    "#add b to Y\n",
    "Z=Y+b\n",
    "print(f'Z.shape = {Z.shape}')\n",
    "# print(Z)\n",
    "#Note: b is automatically broadcast to match the shape of Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d55df",
   "metadata": {},
   "source": [
    "\n",
    "## Part A — Can these two tensors broadcast? If **yes**, what is the result shape?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf9ac9",
   "metadata": {},
   "source": [
    "\n",
    "**A1.** `A: (5, 1, 7)` and `B: (1, 3, 7)`  \n",
    "\n",
    "**A2.** `A: (3, 1, 4)` and `B: (2, 5)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52084dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work (optional): Try constructing dummy tensors to see if operations succeed.\n",
    "# Example for A1:\n",
    "# A = torch.empty(5, 1, 7)\n",
    "# B = torch.empty(1, 3, 7)\n",
    "# print((A + B).shape)  # or any element-wise op\n",
    "#\n",
    "# Example for A2:\n",
    "# A = torch.empty(3, 1, 4)\n",
    "# B = torch.empty(2, 5)\n",
    "# # The following should raise an error if not broadcastable:\n",
    "# # print((A + B).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c2278",
   "metadata": {},
   "source": [
    "\n",
    "## Part B — If broadcasting is possible, **show how** (via `unsqueeze` or  [..,None,..] ), otherwise explain exactly why not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d98875",
   "metadata": {},
   "source": [
    "**B1.** `A: (10, 1, 5)` and `b: (5,)`. Broadcastable? If yes, give the result shape and identify which dimension(s) of which tensor expand.  \n",
    "\n",
    "**B2.** Add a per-example bias: `x: (64, 1, 28, 28)`, `b: (64,)`.  \n",
    "Add `b` to every element of the corresponding sample in `x`. Is this broadcastable? If so, how would you write the addition?\n",
    "\n",
    "**B3.** Multiply an image batch by per-channel scales: `img: (16, 3, 224, 224)`, `w: (1, 3, 1, 1)`.  \n",
    "Is this directly broadcastable? If yes, what expands where?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work (optional):\n",
    "# A = torch.empty(10, 1, 5)\n",
    "# b = torch.empty(5)\n",
    "# # print((A + b).shape)\n",
    "\n",
    "# x = torch.empty(64, 1, 28, 28)\n",
    "# b = torch.empty(64)\n",
    "# # Try adding with a reshaped b:\n",
    "# # y = x + b.view(64, 1, 1, 1)\n",
    "#\n",
    "# img = torch.empty(16, 3, 224, 224)\n",
    "# w = torch.empty(1, 3, 1, 1)\n",
    "# # Try multiplication:\n",
    "# # out = img * w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57ef4f",
   "metadata": {},
   "source": [
    "\n",
    "## Part C — `torch.matmul` broadcasting (batch dims broadcast; matrix dims must align)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13541b7",
   "metadata": {},
   "source": [
    "\n",
    "**C1.** `X: (10, 3, 4)` and `y: (4,)` with `X @ y`.  \n",
    "Valid? If yes, what’s the result shape and why?\n",
    "\n",
    "**C2.** `A: (5, 3, 4)` and `B: (2, 4, 6)` with `A @ B`.  \n",
    "Valid? If not, explain exactly which dimensions fail to broadcast; then propose a small change that would make it valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fcab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work (optional):\n",
    "# X = torch.empty(10, 3, 4)\n",
    "# y = torch.empty(4)\n",
    "# # print((X @ y).shape)\n",
    "#\n",
    "# A = torch.empty(5, 3, 4)\n",
    "# B = torch.empty(2, 4, 6)\n",
    "# # This will error because batch dims (5) and (2) do not broadcast:\n",
    "# # print((A @ B).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84c477",
   "metadata": {},
   "source": [
    "\n",
    "## Part D — Practical refactoring (“can it broadcast, and if so how?”)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc8738",
   "metadata": {},
   "source": [
    "\n",
    "**D1.** You have `scores: (batch=128, heads=4, query_len=50, key_len=50)` and `pad: (batch=128, key_len=50)` with 0s for keep and −inf for masked positions.  \n",
    "Without allocating a large temporary, show how to apply `pad` to `scores` using broadcasting. What view/unsqueeze shape should `pad` take?\n",
    "\n",
    "**D2.** Subtract a per-channel mean from NCHW activations: `x: (64, 3, 32, 32)`, `mean: (3,)`.  \n",
    "Show two equivalent approaches: one explicit via indexing/unsqueeze, one idiomatic relying on broadcasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09370b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work (optional):\n",
    "# scores = torch.empty(128, 4, 50, 50)\n",
    "# pad = torch.empty(128, 50)\n",
    "# # Apply broadcasting mask over last dimension (key_len):\n",
    "# # scores = scores + pad.view(128, 1, 1, 50)\n",
    "#\n",
    "# x = torch.empty(64, 3, 32, 32)\n",
    "# mean = torch.empty(3)\n",
    "# # Explicit:\n",
    "# # y1 = x - mean.view(1, 3, 1, 1)\n",
    "# # Idiomatic:\n",
    "# # y2 = x - mean[None, :, None, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e1d187",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Answer Key\n",
    "\n",
    "### Part A\n",
    "**A1.** Yes → result shape **(5, 3, 7)**.  \n",
    "Right-to-left: `7 vs 7` ✔, `1 vs 3` → `1` expands to `3`, `5 vs 1` → `1` expands to `5`.\n",
    "\n",
    "**A2.** **No.** Rightmost dims `4` (from `(3,1,4)`) and `5` (from `(2,5)`) conflict and neither is `1`.\n",
    "\n",
    "### Part B\n",
    "\n",
    "**B1.** Yes → result **(10, 1, 5)**.  \n",
    "`b: (5,)` behaves like `(1, 5)` and expands across the `10` and `1` leading dims of `A`.\n",
    "\n",
    "**B2.** Yes. Add with a reshaped bias:  \n",
    "`y = x + b.view(64, 1, 1, 1)` (or `b[:, None, None, None]`). The `1`s broadcast across spatial dims and the sample-aligned `64` matches.\n",
    "\n",
    "**B3.** Yes. `(16, 3, 224, 224) * (1, 3, 1, 1)` → result `(16, 3, 224, 224)`.  \n",
    "Batch `16` expands from `1` in `w`; channels match at `3`; spatial `224`s match.\n",
    "\n",
    "### Part C\n",
    "**C1.** Valid → result **(10, 3)**.  \n",
    "Each `(3×4)` matrix in `X` multiplies the `(4,)` vector (treated as `(4,1)` then squeezed), yielding `(3,)` per batch; batch size `10` is preserved.\n",
    "\n",
    "**C2.** **Invalid** as given.  \n",
    "Batch dims are `(5)` vs `(2)`, which **do not broadcast** (neither is `1`). Matrix inner dims `4 @ 4` are fine.  \n",
    "**Fix:** Use a single shared `B`, e.g. make `B` shape `(4, 6)` or `(1, 4, 6)`, or repeat to `(5, 4, 6)` explicitly if you truly have two distinct `B`s and want to tile.\n",
    "\n",
    "### Part D\n",
    "**D1.** View `pad` as `(128, 1, 1, 50)` and add:  \n",
    "`scores = scores + pad.view(128, 1, 1, 50)`  \n",
    "This broadcasts `pad` across `heads` and `query_len` while aligning to the last (key) dimension.\n",
    "\n",
    "**D2.** Two equivalent approaches:  \n",
    "- **Explicit:** `y1 = x - mean.view(1, 3, 1, 1)`  \n",
    "- **Idiomatic:** `y2 = x - mean[None, :, None, None]`\n",
    "\n",
    "---\n",
    "\n",
    "**Optional sanity-check cell (run locally):** Try constructing dummy tensors with the shapes above and performing the ops to observe resulting shapes or errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64eb710",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
