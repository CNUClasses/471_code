{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826121d3",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch in 75 Minutes \n",
    "\n",
    "**Pre Reqs:** basic Python/NumPy  \n",
    "**Goal:** Leave ready to read PyTorch code, build/train simple models, and debug common issues.\n",
    "\n",
    "**What you'll learn**\n",
    "1. Tensors & vectorization (device, dtype, shapes, broadcasting)\n",
    "2. Autograd: building and differentiating computation graphs\n",
    "3. `nn.Module`, losses, and optimizers\n",
    "4. Input pipelines with `Dataset` / `DataLoader`\n",
    "5. Canonical training & evaluation loops (+ checkpoints)\n",
    "6. Mini project (MNIST)\n",
    "7. Performance tips: `torch.compile`, mixed precision\n",
    "8. Common gotchas and debugging patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca3875",
   "metadata": {},
   "source": [
    "## 0–5 min — Framing & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7465e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Environment & reproducibility\n",
    "import sys, math, time, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "#the following determines if we use the GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device in use:\", device)\n",
    "\n",
    "#for reproducibility, set all random seeds to a fixed value\n",
    "torch.manual_seed(123)\n",
    "random.seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c56369",
   "metadata": {},
   "source": [
    "### <mark>Why Pytorch instead of Numpy?\n",
    "\n",
    "<mark>It can use a GPU as well as a CPU<br>\n",
    "It can compute gradients automatically (autograd)<br>\n",
    "It has a lot of useful functions for deep learning (e.g. layers, loss fns, optimizers, etc.)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761dc7",
   "metadata": {},
   "source": [
    "\n",
    "## 5–15 min — Tensors & Vectorization\n",
    "Key ideas: **device**, **dtype**, **shapes**, **broadcasting**, and avoiding Python loops.<br>\n",
    "<mark>See broadcasting notebook for further broadcasting details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create tensors directly on the chosen device\n",
    "x = torch.arange(12, dtype=torch.float32, device=device).reshape(3, 4)\n",
    "w = torch.randn(4, 2, device=device)\n",
    "b = torch.zeros(2, device=device)\n",
    "\n",
    "y = x @ w + b  # broadcast bias\n",
    "print(f\"shapes: x.shape={x.shape}, w.shape={w.shape}, y.shape={y.shape}, b.shape={b.shape}\")\n",
    "print(y[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Broadcasting demo\n",
    "a = torch.randn(8, 1, 6, device=device)\n",
    "c = torch.randn(1, 5, 6, device=device)\n",
    "out = a + c  # -> [8, 5, 6]\n",
    "print(\"Broadcasted shape:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e069c7",
   "metadata": {},
   "source": [
    "\n",
    "**Notes**\n",
    "- Prefer constructing on the right device (`device=device`) or use `.to(device)`.\n",
    "- `view` vs `reshape`: `view` requires contiguous memory; `reshape` is safer and may copy.\n",
    "- Use vectorized operations; avoid explicit Python loops for math on tensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecd07e",
   "metadata": {},
   "source": [
    "## 15–25 min — Autograd (automatic differentiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd113c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scalar function and its gradient\n",
    "x = torch.tensor([2.0], requires_grad=True, device=device)\n",
    "y = x**2 + 3*x + 1            # dy/dx = 2x + 3 = 7 when x=2\n",
    "y.backward()\n",
    "print(\"x.grad:\", x.grad)\n",
    "print(\"y.requires_grad:\", y.requires_grad)\n",
    "\n",
    "\n",
    "# Grads accumulate: zero them if reusing tensors\n",
    "x.grad.zero_()\n",
    "print(\"x.grad:\", x.grad)\n",
    "y2 = (x * 5 + 1)\n",
    "y2.backward()\n",
    "print(\"x.grad after second backward:\", x.grad)\n",
    "\n",
    "# Detach and no_grad\n",
    "x2 = (x.detach() * 10)        # breaks graph\n",
    "print(\"x2.requires_grad:\", x2.requires_grad)\n",
    "y2 = (x2 * 5 + 1)\n",
    "# y2.backward()            # throws exception\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = x * 7 + 1               # won't track gradients\n",
    "    print(\"z.requires_grad:\", z.requires_grad)\n",
    "    # z.backward()                # throws exception\n",
    "print(\"no_grad result:\", z.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bf0c0",
   "metadata": {},
   "source": [
    "\n",
    "**Pitfalls**\n",
    "- Gradients **accumulate**; be sure to zero them between steps.\n",
    "- Wrap evaluation in `torch.no_grad()` to save memory/compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eac5b7",
   "metadata": {},
   "source": [
    "## 25–40 min — `nn.Module`, Losses, Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ac804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):   #pytorch equivalent to our Numpy MLP class\n",
    "    def __init__(self, in_dim=784, hid=256, out_dim=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP().to(device)    #put on device of choice (GPU or CPU)\n",
    "# criterion = nn.MSELoss()    #pytorch equivalent to the mean square loss we calcualed using numpy and the Value class\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)    #pytorch equivalent of the gradient descent algorithm we implemented using numpy and the value class\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)    #pytorch equivalent of the gradient descent algorithm we implemented using numpy and the value class\n",
    "\n",
    "\n",
    "print(\"Total trainable model params=\", sum(p.numel() for p in model.parameters())/1e6, \"Million\")  # 1st layer=(784*256 + 256 biases), 2nd layer=256*10 + 10 biases = 0.2M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c2210",
   "metadata": {},
   "source": [
    "\n",
    "**Notes**\n",
    "- For classification with integer labels, use `nn.CrossEntropyLoss` with **logits** (no softmax).\n",
    "- For regression, `nn.MSELoss` and ensure shapes align (`[N, 1]` vs `[N]`).\n",
    "- Common optimizers: `SGD` and `Adam`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eba7dd",
   "metadata": {},
   "source": [
    "## 40–55 min — Input Pipelines: `Dataset` / `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A tiny synthetic classification dataset\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, n=1024, d=20):\n",
    "        g = torch.Generator().manual_seed(0)\n",
    "        self.x = torch.randn(n, d, generator=g)\n",
    "        true_w = torch.randn(d, 1, generator=g)\n",
    "        logits = self.x @ true_w + 0.25 * torch.randn(n, 1, generator=g)\n",
    "        self.y = (logits.squeeze() > 0).long()     # {0,1}\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, idx): return self.x[idx], self.y[idx]\n",
    "\n",
    "train_ds = ToyDataset(2048, d=20)\n",
    "test_ds  = ToyDataset(512, d=20)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch shapes:\", xb.shape, yb.shape, \"| dtypes:\", xb.dtype, yb.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd656c4b",
   "metadata": {},
   "source": [
    "## 55–65 min — Canonical Training & Evaluation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device=device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        if xb.dim() > 2:\n",
    "            xb = xb.view(xb.size(0), -1)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device=device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        if xb.dim() > 2:\n",
    "            xb = xb.view(xb.size(0), -1)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "# Quick demo training on synthetic data\n",
    "demo_model = MLP(in_dim=20, hid=64, out_dim=2).to(device)\n",
    "demo_criterion = nn.CrossEntropyLoss()\n",
    "demo_optimizer = torch.optim.Adam(demo_model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(2):\n",
    "    tr_loss, tr_acc = train_one_epoch(demo_model, train_loader, demo_optimizer, demo_criterion, device)\n",
    "    te_loss, te_acc = evaluate(demo_model, test_loader, demo_criterion, device)\n",
    "    print(f\"epoch {epoch+1}: train_loss={tr_loss:.3f} acc={tr_acc:.3f} | \"\n",
    "          f\"test_loss={te_loss:.3f} acc={te_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a0d96",
   "metadata": {},
   "source": [
    "### Checkpointing (save & load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f79be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save\n",
    "torch.save({\n",
    "    \"model\": demo_model.state_dict(),\n",
    "    \"opt\": demo_optimizer.state_dict()\n",
    "}, \"ckpt_demo.pt\")\n",
    "print(\"Saved to ckpt_demo.pt\")\n",
    "\n",
    "# Load\n",
    "ckpt = torch.load(\"ckpt_demo.pt\", map_location=device)\n",
    "demo_model.load_state_dict(ckpt[\"model\"])\n",
    "demo_optimizer.load_state_dict(ckpt[\"opt\"])\n",
    "print(\"Reloaded checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e1a10",
   "metadata": {},
   "source": [
    "## 65–70 min — Mini Project: MNIST in ~30 Lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try torchvision/MNIST\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "try:\n",
    "    train_set = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "    test_set  = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=tfm)\n",
    "except Exception as e:\n",
    "    print(\"MNIST download failed, switching to fallback:\", e)\n",
    "    use_mnist = False\n",
    "\n",
    "train_loader_m = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader_m  = DataLoader(test_set,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "model_m = MLP(in_dim=28*28, hid=256, out_dim=10).to(device)\n",
    "opt_m = torch.optim.Adam(model_m.parameters(), lr=1e-3)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "for epoch in range(1):\n",
    "    tr_l, tr_a = train_one_epoch(model_m, train_loader_m, opt_m, ce, device)\n",
    "    te_l, te_a = evaluate(model_m, test_loader_m, ce, device)\n",
    "    print(f\"[MNIST] epoch {epoch+1}: train_acc={tr_a:.3f} test_acc={te_a:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57634d2",
   "metadata": {},
   "source": [
    "## 70–73 min — Performance & Modern Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8827a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.compile (PyTorch 2.x). May not speed up every model; test on your hardware.\n",
    "try:\n",
    "    compiled_demo = torch.compile(demo_model)  # reuses earlier demo model\n",
    "    print(\"Compiled model OK.\")\n",
    "except Exception as e:\n",
    "    print(\"torch.compile not available or failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mixed precision: speedups on GPUs with tensor cores\n",
    "scaler = None\n",
    "if torch.cuda.is_available():\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    print(\"Using GradScaler for mixed precision on CUDA.\")\n",
    "else:\n",
    "    print(\"CUDA not available; skipping mixed precision demo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1e72e",
   "metadata": {},
   "source": [
    "\n",
    "**Tips**\n",
    "- Increase `DataLoader(num_workers, pin_memory=True)` for faster host→device transfer.\n",
    "- Try `torch.backends.cudnn.benchmark = True` for convnets with static shapes.\n",
    "- Profile before optimizing; verify correctness after any performance tweaks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e2d38",
   "metadata": {},
   "source": [
    "## 73–75 min — Gotchas, Debugging, Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a44fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Common checks\n",
    "try:\n",
    "    print(\"xb dtype/device:\", xb.dtype, xb.device)\n",
    "except NameError:\n",
    "    print(\"Run the DataLoader cell first to define a sample batch (xb).\")\n",
    "\n",
    "print(\"First parameter device:\", next(demo_model.parameters()).device)\n",
    "\n",
    "# NaN/Inf scan (example)\n",
    "bad = []\n",
    "for name, p in demo_model.named_parameters():\n",
    "    if torch.isnan(p).any() or torch.isinf(p).any():\n",
    "        bad.append(name)\n",
    "print(\"Params with NaN/Inf:\", bad or \"None\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1691746",
   "metadata": {},
   "source": [
    "\n",
    "### Where to go next\n",
    "- **Vision:** `nn.Conv2d`, padding/stride/dilation, `torchvision.models`\n",
    "- **Sequence/Language:** `nn.Transformer`, `torchtext`, Hugging Face integration\n",
    "- **Extras:** Schedulers, custom losses/metrics, model quantization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd1007",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
