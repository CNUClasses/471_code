{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be53b476",
   "metadata": {},
   "source": [
    "\n",
    "# PyTorch `Conv2d` Practice — Shapes, Hyperparameters, and Parameter Counts\n",
    "\n",
    "\n",
    "**What you'll do:**\n",
    "- Practice computing **output shapes** for `Conv2d` given **kernel size, stride, padding, dilation**.\n",
    "- Design hyperparameter **combinations** to reach a **target output size** from a given input.\n",
    "- Understand **parameter sharing**, compute **trainable parameters** per filter and per layer.\n",
    "- Compare conv parameter counts to an equivalent **fully connected (MLP)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7151b",
   "metadata": {},
   "source": [
    "## Setup & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3bf640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def _to_pair(x):\n",
    "    if isinstance(x, tuple): return x\n",
    "    return (x, x)\n",
    "\n",
    "def conv2d_output_hw(H, W, kernel_size=3, stride=1, padding=0, dilation=1):\n",
    "    \"\"\"Compute (H_out, W_out) for Conv2d using PyTorch's formula.\n",
    "    out = floor((in + 2*pad - dilation*(kernel-1) - 1)/stride + 1)\n",
    "    Accepts ints or (h,w) tuples for kernel_size/stride/padding/dilation.\n",
    "    \"\"\"\n",
    "    kH, kW = _to_pair(kernel_size)\n",
    "    sH, sW = _to_pair(stride)\n",
    "    pH, pW = _to_pair(padding)\n",
    "    dH, dW = _to_pair(dilation)\n",
    "    H_out = math.floor((H + 2*pH - dH*(kH-1) - 1)/sH + 1)\n",
    "    W_out = math.floor((W + 2*pW - dW*(kW-1) - 1)/sW + 1)\n",
    "    return H_out, W_out\n",
    "\n",
    "def conv2d_output_shape(C_in, H, W, C_out, **kwargs):\n",
    "    H2, W2 = conv2d_output_hw(H, W, **kwargs)\n",
    "    return (C_out, H2, W2)\n",
    "\n",
    "def enumerate_combos(H, W, H_target, W_target,\n",
    "                     ks_range=(1,7), stride_range=(1,3), pad_range=(0,5), dil_range=(1,3)):\n",
    "    \"\"\"Enumerate (kH,kW),(sH,sW),(pH,pW),(dH,dW) that map (H,W)->(H_target,W_target).\n",
    "    Ranges are inclusive small search windows.\n",
    "    \"\"\"\n",
    "    sols = []\n",
    "    for k in range(ks_range[0], ks_range[1]+1):\n",
    "        for s in range(stride_range[0], stride_range[1]+1):\n",
    "            for p in range(pad_range[0], pad_range[1]+1):\n",
    "                for d in range(dil_range[0], dil_range[1]+1):\n",
    "                    h2, w2 = conv2d_output_hw(H, W, kernel_size=k, stride=s, padding=p, dilation=d)\n",
    "                    if h2 == H_target and w2 == W_target:\n",
    "                        sols.append(((k,k),(s,s),(p,p),(d,d)))\n",
    "    return sols\n",
    "\n",
    "def same_padding_for(kernel_size, dilation=1, stride=1):\n",
    "    \"\"\"For stride=1, return padding that preserves spatial size (if integer).\n",
    "    Uses effective_kernel = dilation*(k-1) + 1, padding = (effective_kernel - 1)/2\n",
    "    \"\"\"\n",
    "    k = kernel_size\n",
    "    eff = dilation*(k-1) + 1\n",
    "    pad = (eff - 1) / 2\n",
    "    return pad  # may be non-integer if (k,d) incompatible with exact 'same'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23f726",
   "metadata": {},
   "source": [
    "\n",
    "## Part A — Output Shape Practice\n",
    "\n",
    "Use the formula (and optionally the helper) to compute output sizes. Then verify with PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fede56",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem A1**  \n",
    "Input **(C=3, H=32, W=32)** → Conv2d with:\n",
    "- `out_channels=16`, `kernel_size=3`, `stride=1`, `padding=1`, `dilation=1`  \n",
    "**Task:** Compute the output shape `(C_out, H_out, W_out)`.\n",
    "\n",
    "<mark>H_out = floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d87bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer (fill mentally): (16, 32, 32) expected\n",
      "Helper: (16, 32, 32)\n",
      "PyTorch: (16, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Compute by hand, then check with helper\n",
    "H_out, W_out = conv2d_output_hw(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "print(\"Your answer (fill mentally): (16, 32, 32) expected\")\n",
    "print(\"Helper:\", (16, H_out, W_out))\n",
    "\n",
    "# Verify by PyTorch\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "y = conv(x)\n",
    "print(\"PyTorch:\", tuple(y.shape[1:]))  # (C_out,H_out,W_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1830aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer (fill mentally): (16, 32, 32) expected\n",
      "Helper: (16, 34, 34)\n",
      "PyTorch: (16, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "#test problem\n",
    "# TODO: Compute by hand, then check with helper\n",
    "H_out, W_out = conv2d_output_hw(64, 64, kernel_size=3, stride=2, padding=2, dilation=0)\n",
    "print(\"Your answer (fill mentally): (16, 32, 32) expected\")\n",
    "print(\"Helper:\", (16, H_out, W_out))\n",
    "\n",
    "# Verify by PyTorch\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "y = conv(x)\n",
    "print(\"PyTorch:\", tuple(y.shape[1:]))  # (C_out,H_out,W_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b3046",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem A2**  \n",
    "Input **(C=1, H=28, W=28)** → Conv2d with:\n",
    "- `out_channels=32`, `kernel_size=3`, `stride=2`, `padding=1`, `dilation=1`  \n",
    "**Task:** Compute `(32, H_out, W_out)`.\n",
    "\n",
    "<mark>H_out = floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71879690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H_out, W_out = conv2d_output_hw(28, 28, kernel_size=3, stride=2, padding=1, dilation=1)\n",
    "print(\"Helper:\", (32, H_out, W_out))\n",
    "\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "conv = nn.Conv2d(1, 32, 3, stride=2, padding=1, dilation=1, bias=False)\n",
    "print(\"PyTorch:\", tuple(conv(x).shape[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406bc2e",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem A3** (asymmetric hyperparameters)  \n",
    "Input **(C=8, H=128, W=128)** → Conv2d with:\n",
    "- `out_channels=8`, `kernel_size=(3,5)`, `stride=(2,1)`, `padding=(1,2)`, `dilation=(1,1)`  \n",
    "**Task:** Compute `(8, H_out, W_out)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19da5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H_out, W_out = conv2d_output_hw(128, 128, kernel_size=(3,5), stride=(2,1), padding=(1,2), dilation=(1,1))\n",
    "print(\"Helper:\", (8, H_out, W_out))\n",
    "\n",
    "x = torch.randn(1, 8, 128, 128)\n",
    "conv = nn.Conv2d(8, 8, kernel_size=(3,5), stride=(2,1), padding=(1,2), dilation=(1,1), bias=False)\n",
    "print(\"PyTorch:\", tuple(conv(x).shape[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d027b0",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem A4** (dilation)  \n",
    "Input **(C=3, H=64, W=96)** → Conv2d with:\n",
    "- `out_channels=12`, `kernel_size=7`, `stride=2`, `padding=3`, `dilation=2`  \n",
    "**Task:** Compute `(12, H_out, W_out)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3102e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H_out, W_out = conv2d_output_hw(64, 96, kernel_size=7, stride=2, padding=3, dilation=2)\n",
    "print(\"Helper:\", (12, H_out, W_out))\n",
    "\n",
    "x = torch.randn(1, 3, 64, 96)\n",
    "conv = nn.Conv2d(3, 12, kernel_size=7, stride=2, padding=3, dilation=2, bias=False)\n",
    "print(\"PyTorch:\", tuple(conv(x).shape[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed5946",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem A5** (“same” size with dilation)  \n",
    "For **stride=1**, find the **padding** needed to preserve size `H_out=H` for a given `kernel_size` and `dilation`.\n",
    "\n",
    "- Formula: `effective_kernel = dilation*(kernel - 1) + 1`, then  \n",
    "  `padding = (effective_kernel - 1)/2` (must be an integer to be exact).\n",
    "\n",
    "**Task:** For `H=W=32`, `kernel_size=3`, `dilation=3`, `stride=1` — compute the padding that preserves size.\n",
    "\n",
    "<mark>H_out = floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb114ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pad = same_padding_for(kernel_size=3, dilation=3, stride=1)\n",
    "print(\"Required padding (per side):\", pad, \"→ use padding=3 to keep size with stride=1\")\n",
    "print(\"Check:\", conv2d_output_hw(32, 32, kernel_size=3, stride=1, padding=3, dilation=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfce893",
   "metadata": {},
   "source": [
    "\n",
    "## Part B — Design Hyperparameters to Hit a Target Size\n",
    "\n",
    "Given input `(H, W)` and a **target** `(H_target, W_target)`, propose `(kernel, stride, padding, dilation)` that achieve it.\n",
    "Try by hand first, then use the enumerator to check/collect solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed90e40",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem B1**  \n",
    "Input `H=W=32` → Target `H=W=16`. Propose **three** different `(k, s, p, d)` combos.\n",
    "\n",
    "<mark>H_out = floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9526fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sols = enumerate_combos(32, 32, 16, 16,\n",
    "                        ks_range=(1,7), stride_range=(1,3), pad_range=(0,5), dil_range=(1,3))\n",
    "print(f\"Found {len(sols)} combos (showing first 10):\")\n",
    "for i, sol in enumerate(sols[:10]):\n",
    "    (k,_),(s,_),(p,_),(d,_) = sol\n",
    "    print(f\"{i+1:02d}: k={k}, s={s}, p={p}, d={d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d63a16",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem B2**  \n",
    "Input `H=W=64` → Target `H=W=31`. Find **one** valid set `(k, s, p, d)`.\n",
    "\n",
    "<mark>H_out = floor((H_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sols = enumerate_combos(64, 64, 31, 31,\n",
    "                        ks_range=(1,7), stride_range=(1,3), pad_range=(0,7), dil_range=(1,3))\n",
    "print(\"Some solutions:\", sols[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b0efe",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem B3**  \n",
    "Input `(H, W) = (72, 96)` → Target `(36, 48)`. Propose at least **two** solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cfcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sols = enumerate_combos(72, 96, 36, 48,\n",
    "                        ks_range=(1,7), stride_range=(1,3), pad_range=(0,5), dil_range=(1,3))\n",
    "print(f\"Solutions found: {len(sols)} (first 10):\")\n",
    "for sol in sols[:1]: print(sol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93d3ec",
   "metadata": {},
   "source": [
    "\n",
    "## Part C — Parameter Sharing & Trainable Parameter Counts\n",
    "\n",
    "**Key idea:** In conv layers, a small filter (e.g., 3×3×C_in) is **shared** across all spatial positions.  \n",
    "You learn that filter **once**, then slide it over the image. This yields **far fewer parameters** than a fully connected layer over all pixels.\n",
    "\n",
    "**Counts:**\n",
    "- **Per filter:** params = `kH * kW * C_in` (+ 1 bias if used)\n",
    "- **Per layer with `C_out` filters:** params = `(kH*kW*C_in + bias) * C_out` where `bias` is 1 if enabled else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv2d_param_count(C_in, C_out, kH, kW, bias=True):\n",
    "    per_filter = kH * kW * C_in + (1 if bias else 0)\n",
    "    return per_filter * C_out\n",
    "\n",
    "def mlp_param_count(sizes, bias=True):\n",
    "    \"\"\"sizes = [in_dim, h1, h2, ..., out_dim]\"\"\"\n",
    "    total = 0\n",
    "    for a, b in zip(sizes[:-1], sizes[1:]):\n",
    "        total += a * b + (b if bias else 0)\n",
    "    return total\n",
    "\n",
    "# Examples\n",
    "print(\"Conv example (C_in=3, C_out=64, k=3x3, bias=True):\",\n",
    "      conv2d_param_count(3, 64, 3, 3, bias=True))\n",
    "\n",
    "print(\"Two conv layers stack:\")\n",
    "p1 = conv2d_param_count(3, 32, 3, 3, bias=True)\n",
    "p2 = conv2d_param_count(32, 64, 3, 3, bias=True)\n",
    "print(\"  layer1:\", p1, \"  layer2:\", p2, \"  total:\", p1+p2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54caf3f3",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem C1**  \n",
    "Compute params for: `C_in=3, C_out=64, kernel=5×5`, with and without bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cf2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"With bias:\", conv2d_param_count(3, 64, 5, 5, bias=True))\n",
    "print(\"No bias :\", conv2d_param_count(3, 64, 5, 5, bias=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f3d2be",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem C2**  \n",
    "Two-layer conv stack:  \n",
    "- Layer1: `C_in=3 → C_out=16`, `k=3×3`, bias **True**  \n",
    "- Layer2: `C_in=16 → C_out=32`, `k=3×3`, bias **False**  \n",
    "**Task:** Compute total trainable params.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1 = conv2d_param_count(3, 16, 3, 3, bias=True)\n",
    "p2 = conv2d_param_count(16, 32, 3, 3, bias=False)\n",
    "print(\"Total params:\", p1 + p2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a70b28",
   "metadata": {},
   "source": [
    "\n",
    "### **Compare to a Fully Connected MLP**\n",
    "\n",
    "Consider an RGB input **32×32×3** flattened to `3072` units, then an MLP with hidden `256` and output `10` classes:\n",
    "- MLP sizes: `[3072, 256, 10]`  \n",
    "- Conv alternative: `Conv2d(3→64, k=3×3)` followed by `Conv2d(64→64, k=3×3)` followed by max pool 2d.\n",
    "\n",
    "**Task:** Compare parameter counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b961f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_params = mlp_param_count([32*32*3, 256, 10], bias=True)\n",
    "conv_a = conv2d_param_count(3, 64, 3, 3, bias=True)\n",
    "conv_b = conv2d_param_count(64, 64, 3, 3, bias=True)\n",
    "print(\"MLP params:\", mlp_params)\n",
    "print(\"Conv stack params (two 3x3 convs):\", conv_a + conv_b)\n",
    "# print(\"final FC layer in conv net: assumming 32*32*64 input, 10 output:\", mlp_param_count([32*32*64, 10], bias=True))\n",
    "print(\"After max poool2d on output of conv stack (16*16*64 input, 10 output):\", mlp_param_count([16*16*64, 10], bias=True))\n",
    "print(\"Conv net total (with final FC):\", conv_a + conv_b + mlp_param_count([16*16*64, 10], bias=True))\n",
    "\n",
    "#so the final linear layer with the 64 filters is whats blowing up the size of the conv net\n",
    "#can reduce this by using fewer filters in final layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f02076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "def _to_pair(x): return x if isinstance(x, tuple) else (x, x)\n",
    "\n",
    "def conv2d_output_hw(H, W, kernel_size=3, stride=1, padding=0, dilation=1):\n",
    "    kH, kW = _to_pair(kernel_size)\n",
    "    sH, sW = _to_pair(stride)\n",
    "    pH, pW = _to_pair(padding)\n",
    "    dH, dW = _to_pair(dilation)\n",
    "    H_out = math.floor((H + 2*pH - dH*(kH-1) - 1)/sH + 1)\n",
    "    W_out = math.floor((W + 2*pW - dW*(kW-1) - 1)/sW + 1)\n",
    "    return H_out, W_out\n",
    "\n",
    "def conv2d_param_count(C_in, C_out, kH, kW, bias=True):\n",
    "    per_filter = kH * kW * C_in + (1 if bias else 0)\n",
    "    return per_filter * C_out\n",
    "\n",
    "def mlp_param_count(sizes, bias=True):\n",
    "    tot=0\n",
    "    for a,b in zip(sizes[:-1], sizes[1:]):\n",
    "        tot += a*b + (b if bias else 0)\n",
    "    return tot\n",
    "\n",
    "# Part A checks\n",
    "print(\"A1:\", (16,) + conv2d_output_hw(32, 32, 3, 1, 1, 1))\n",
    "print(\"A2:\", (8,)  + conv2d_output_hw(64, 64, 5, 2, 0, 1))\n",
    "print(\"A3:\", (32,) + conv2d_output_hw(28, 28, 3, 2, 1, 1))\n",
    "print(\"A4:\", (8,)  + conv2d_output_hw(128, 128, (3,5), (2,1), (1,2), (1,1)))\n",
    "print(\"A5:\", (12,) + conv2d_output_hw(64, 96, 7, 2, 3, 2))\n",
    "# A6 padding for same with stride=1, k=3, d=3:\n",
    "eff = 3* (3-1) + 1\n",
    "pad = (eff - 1)//2\n",
    "print(\"A6 padding:\", pad)\n",
    "\n",
    "# Part B example solutions (show small subsets)\n",
    "def enumerate_combos(H, W, H_target, W_target,\n",
    "                     ks_range=(1,7), stride_range=(1,3), pad_range=(0,5), dil_range=(1,3)):\n",
    "    sols = []\n",
    "    for k in range(ks_range[0], ks_range[1]+1):\n",
    "        for s in range(stride_range[0], stride_range[1]+1):\n",
    "            for p in range(pad_range[0], pad_range[1]+1):\n",
    "                for d in range(dil_range[0], dil_range[1]+1):\n",
    "                    h2, w2 = conv2d_output_hw(H, W, kernel_size=k, stride=s, padding=p, dilation=d)\n",
    "                    if h2 == H_target and w2 == W_target:\n",
    "                        sols.append((k,s,p,d))\n",
    "    return sols\n",
    "\n",
    "print(\"\\nB1 32→16 examples:\", enumerate_combos(32,32,16,16)[:5])\n",
    "print(\"B2 64→31 examples:\", enumerate_combos(64,64,31,31, pad_range=(0,7))[:5])\n",
    "print(\"B3 72×96→36×48 examples:\", enumerate_combos(72,96,36,48)[:5])\n",
    "\n",
    "# Part C counts\n",
    "print(\"\\nC1 with bias:\",  conv2d_param_count(3, 64, 5, 5, True))\n",
    "print(\"C1 no bias:\",       conv2d_param_count(3, 64, 5, 5, False))\n",
    "\n",
    "p1 = conv2d_param_count(3, 16, 3, 3, True)\n",
    "p2 = conv2d_param_count(16, 32, 3, 3, False)\n",
    "print(\"C2 total:\", p1 + p2)\n",
    "\n",
    "mlp = mlp_param_count([32*32*3, 256, 10], True)\n",
    "convA = conv2d_param_count(3, 64, 3, 3, True)\n",
    "convB = conv2d_param_count(64, 64, 3, 3, True)\n",
    "print(\"MLP params:\", mlp)\n",
    "print(\"Two 3x3 convs params:\", convA + convB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe697b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
