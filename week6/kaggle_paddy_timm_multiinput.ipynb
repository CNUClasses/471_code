{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d6533b",
   "metadata": {},
   "source": [
    "\n",
    "# Paddy Disease Classification — **PyTorch + timm** and Multi‑Head model\n",
    "\n",
    "This notebook demonstrates a **multi‑input** setup using **PyTorch** and and **[timm](https://github.com/huggingface/pytorch-image-models)** (Torch Image Models) for the Kaggle **Paddy** dataset.\n",
    "\n",
    "1) Set up the environment and choose a timm backbone (`convnext_tiny`).  \n",
    "2) Build a **custom Dataset** reading `train.csv` (`image_id`, `label`, `variety`, `age`).  \n",
    "   - Images are stored in subfolders named by **label** (e.g., `train/<label>/<image_id>`).  \n",
    "   - Each sample returns a tuple: **`(image_tensor, variety_idx, age_float, label_idx)`** as requested.  \n",
    "3) Create DataLoaders with timm‑compatible transforms.  \n",
    "4) Define a **multi‑input model**:  \n",
    "   \n",
    "5) Train and evaluate with a minimal, well‑commented loop.\n",
    "\n",
    "> **Note:** Point `DATA_DIR` to your local Kaggle Paddy dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712e2b6",
   "metadata": {},
   "source": [
    "## 1) Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de007fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If timm isn't installed, uncomment:\n",
    "# !pip install timm --quiet\n",
    "\n",
    "import os, random, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "DATA_DIR = Path(\"./data/\")  \n",
    "TRAIN_CSV = DATA_DIR / 'train.csv'\n",
    "TRAIN_IMG_ROOT = DATA_DIR   / 'train_images'\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "#this makes sure that colab instances running this notebook can get to included utils_kp.py\n",
    "try:\n",
    "    import utils_kp as ut\n",
    "except ModuleNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/CNUClasses/471_code/master/week6/utils_kp.py\n",
    "import utils_kp as ut\n",
    " \n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# lr=0.01 #start with this one (its too high see lr finder below)\n",
    "lr=2e-3 #lr finder approved this one\n",
    "NUM_EPOCHS=25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9cb6c1",
   "metadata": {},
   "source": [
    "## 2) Custom Dataset (returns `(image, variety, age, label)`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02edd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# see utils_kp.py for PaddyDataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6049e",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Create datasets with timm transforms \n",
    "\n",
    "Not going to use ImageFolder dataset.  Instead use PaddyMultitaskDataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14265f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'crop_mode': 'center',\n",
      "    'crop_pct': 0.875,\n",
      "    'input_size': (3, 224, 224),\n",
      "    'interpolation': 'bicubic',\n",
      "    'mean': (0.485, 0.456, 0.406),\n",
      "    'std': (0.229, 0.224, 0.225)}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# MODEL_NAME = \"resnet18\"  # try: 'efficientnet_b0', 'convnext_tiny', 'mobilenetv3_large_100', ...\n",
    "MODEL_NAME = 'convnext_tiny'\n",
    "config = timm.data.resolve_data_config({}, model=MODEL_NAME)\n",
    "train_tfms = timm.data.create_transform(**config, is_training=True, hflip=0.5, auto_augment=None)\n",
    "valid_tfms = timm.data.create_transform(**config, is_training=False)\n",
    "\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0600bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes: ['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight', 'blast', 'brown_spot', 'dead_heart', 'downy_mildew', 'hispa', 'normal', 'tungro']\n",
      "Variety classes: ['ADT45', 'AndraPonni', 'AtchayaPonni', 'IR20', 'KarnatakaPonni', 'Onthanel', 'Ponni', 'RR', 'Surya', 'Zonal']\n",
      "Train/Valid/test sizes: 8327 1040 1040\n"
     ]
    }
   ],
   "source": [
    "#get the split datasets\n",
    "train_df, valid_df, test_df=ut.getdataframes(DATA_DIR, TRAIN_CSV, TRAIN_IMG_ROOT, valid_pct=0.1, test_pct=0.1,verbose=True )\n",
    "\n",
    "train_ds = ut.PaddyMultitaskDataset(train_df, TRAIN_IMG_ROOT, transform=train_tfms)\n",
    "valid_ds = ut.PaddyMultitaskDataset(valid_df,   TRAIN_IMG_ROOT, transform=valid_tfms)\n",
    "test_ds  = ut.PaddyMultitaskDataset(test_df,  TRAIN_IMG_ROOT, transform=valid_tfms)\n",
    "\n",
    "print('Label classes:', train_ds.labels)\n",
    "print('Variety classes:', train_ds.varieties)\n",
    "print('Train/Valid/test sizes:', len(train_ds), len(valid_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e93f40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bacterial_leaf_blight',\n",
       " 'bacterial_leaf_streak',\n",
       " 'bacterial_panicle_blight',\n",
       " 'blast',\n",
       " 'brown_spot',\n",
       " 'dead_heart',\n",
       " 'downy_mildew',\n",
       " 'hispa',\n",
       " 'normal',\n",
       " 'tungro']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=train_ds.labels\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f6870",
   "metadata": {},
   "source": [
    "## 3) Create Dataloaders\n",
    "\n",
    "- Shuffle the training loader; keep validation loader deterministic.  \n",
    "- Adjust `BATCH_SIZE` to fit your GPU/CPU memory.\n",
    "\n",
    "This is a datascience competition:<br>\n",
    "the train_images folder contains images with class membership info (in the train.csv file).<br>\n",
    "the test_images folder contains images that your model infers membership on.  These inferences are bundled into a file (see sample_submission.csv) which is submitted for ranking  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afefd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes: torch.Size([256, 3, 224, 224]) torch.Size([256]) torch.Size([256]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "xb, y_var, y_age, y_lbl = next(iter(train_loader))\n",
    "print('Batch shapes:', xb.shape, y_var.shape, y_age.shape, y_lbl.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567303c6",
   "metadata": {},
   "source": [
    "## 4) Load Multi‑input timm Model (Transfer Learning with **timm**)\n",
    "\n",
    "- Use the train/test/val split to test this out\n",
    "Model will now only predict label class\n",
    "- **Warm-up:** freeze backbone; train the classifier head first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baba8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class MultiModalClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Predicts the disease label (10 classes) from:\n",
    "      - image (RGB tensor, e.g. [B,3,H,W])\n",
    "      - variety (categorical index, int in [0..num_variety_classes-1])\n",
    "      - age (normalized float scalar per sample)\n",
    "\n",
    "    Pipeline:\n",
    "      image --(timm backbone + global pool)--> feats   (B, feat_dim)\n",
    "      variety_idx --(one_hot)--> one_hot_var           (B, num_variety_classes)\n",
    "      age_norm  -------------------------------------> (B, 1)\n",
    "      concat([feats, one_hot_var, age_norm]) --MLP--> logits_label (B, num_label_classes)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"convnext_tiny\",\n",
    "        num_label_classes: int = 10,\n",
    "        num_variety_classes: int = 10,\n",
    "        pretrained: bool = True,\n",
    "        mlp_hidden: int = 256,\n",
    "        dropout: float = 0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) CNN backbone with no classifier so we can get a pooled feature vector\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, pretrained=pretrained, num_classes=0, global_pool=\"avg\"\n",
    "        )\n",
    "        feat_dim = self.backbone.num_features\n",
    "\n",
    "        # 2) Remember variety class count for one-hot\n",
    "        self.num_variety_classes = num_variety_classes\n",
    "\n",
    "        # 3) Fusion MLP head (features + one-hot(variety) + age)\n",
    "        fused_in = feat_dim + num_variety_classes + 1  # +1 for age scalar\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(fused_in, mlp_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden, num_label_classes),  # final logits for label prediction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is a tuple: (images, variety_idx, age_norm)\n",
    "          - images: float tensor [B, 3, H, W]\n",
    "          - variety_idx: long/int tensor [B] (values in [0..num_variety_classes-1])\n",
    "          - age_norm: float tensor [B] or [B,1] (already normalized)\n",
    "        returns:\n",
    "          - logits_label: tensor [B, num_label_classes]\n",
    "        \"\"\"\n",
    "        images, variety_idx, age_norm = x  # unpack the tuple\n",
    "\n",
    "        # Backbone features (B, feat_dim)\n",
    "        feats = self.backbone(images)\n",
    "\n",
    "        # One-hot encode variety (B, num_variety_classes)\n",
    "        # F.one_hot expects Long dtype and returns int; cast to float for concat\n",
    "        one_hot_var = F.one_hot(variety_idx.long(), num_classes=self.num_variety_classes).float()\n",
    "\n",
    "        # Ensure age is shape (B,1)\n",
    "        if age_norm.dim() == 1:\n",
    "            age_norm = age_norm.unsqueeze(1)\n",
    "        age_norm = age_norm.float()\n",
    "\n",
    "        # Concatenate along feature dimension\n",
    "        fused = torch.cat([feats, one_hot_var, age_norm], dim=1)\n",
    "\n",
    "        # MLP head -> logits for label prediction\n",
    "        logits_label = self.mlp(fused)\n",
    "        return logits_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89997408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params (heads only): 202250\n"
     ]
    }
   ],
   "source": [
    "model = MultiModalClassifier(\n",
    "    model_name=\"convnext_tiny\",\n",
    "    num_label_classes=10,\n",
    "    num_variety_classes=10,\n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "print('Trainable params (heads only):', sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a411ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see the model structure\n",
    "# print(model.backbone)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8d2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure just training the last layer\n",
    "# for name, p in model.named_parameters():\n",
    "#     print (f'Name={name},p.shape={p.shape}, p.requires_grad = {p.requires_grad}')\n",
    "\n",
    "#stopped here 10/1/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdb817",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Optimizer & loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a239fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single head now\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c23d6",
   "metadata": {},
   "source": [
    "# 6) Training & validation loop\n",
    "\n",
    "- Log train/valid **loss** and **accuracy** per epoch.  \n",
    "- warm up heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d46c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 1.5192 acc 0.472 | valid loss 0.9755 acc 0.665\n",
      "Epoch 02 | train loss 1.1261 acc 0.613 | valid loss 0.8298 acc 0.709\n",
      "Epoch 03 | train loss 0.9844 acc 0.660 | valid loss 0.7184 acc 0.754\n",
      "Epoch 04 | train loss 0.9046 acc 0.692 | valid loss 0.6148 acc 0.783\n",
      "Epoch 05 | train loss 0.8317 acc 0.717 | valid loss 0.5665 acc 0.805\n",
      "Epoch 06 | train loss 0.7944 acc 0.730 | valid loss 0.5155 acc 0.829\n",
      "Epoch 07 | train loss 0.7375 acc 0.751 | valid loss 0.4664 acc 0.854\n",
      "Epoch 08 | train loss 0.7068 acc 0.761 | valid loss 0.4437 acc 0.858\n",
      "Epoch 09 | train loss 0.6879 acc 0.762 | valid loss 0.4704 acc 0.843\n",
      "Epoch 10 | train loss 0.6625 acc 0.772 | valid loss 0.4118 acc 0.862\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for images, variety_idx, age_norm, label_idx in loader:\n",
    "        images      = images.to(device)\n",
    "        variety_idx = variety_idx.to(device)\n",
    "        age_norm    = age_norm.to(device)\n",
    "        label_idx   = label_idx.to(device)\n",
    "\n",
    "        \n",
    "        logits = model((images, variety_idx, age_norm))\n",
    "        loss = criterion(logits, label_idx) #loss is the avearege over the batch (so multiply by batch size below)\n",
    " \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (logits.argmax(1) == label_idx).sum().item()\n",
    "        total += images.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for images, variety_idx, age_norm, label_idx in loader:\n",
    "        images      = images.to(device)\n",
    "        variety_idx = variety_idx.to(device)\n",
    "        age_norm    = age_norm.to(device)\n",
    "        label_idx   = label_idx.to(device)\n",
    "\n",
    "        logits = model((images, variety_idx, age_norm))\n",
    "        loss = criterion(logits, label_idx)  #loss is the avearege over the batch (so multiply by batch size below)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        correct += (logits.argmax(1) == label_idx).sum().item()\n",
    "        total += images.size(0)\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "def train_and_evaluate(model, train_loader, valid_loader, optimizer, criterion, num_epochs=10):\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train for one epoch\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        va_loss, va_acc = evaluate(model, valid_loader, criterion)\n",
    "        print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} | valid loss {va_loss:.4f} acc {va_acc:.3f}\")\n",
    "\n",
    "train_and_evaluate(model, train_loader, valid_loader, optimizer, criterion, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72f395f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     run_loss, correct_label, correct_variety, mae_age \u001b[38;5;241m=\u001b[39m evaluate(model, loader, criterion, device, weights\u001b[38;5;241m=\u001b[39mloss_weights)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m acc_label=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_label\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m acc_variety=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_variety\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28meval\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36meval\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(loader\u001b[38;5;241m=\u001b[39mtest_loader):\n\u001b[0;32m----> 2\u001b[0m     run_loss, correct_label, correct_variety, mae_age \u001b[38;5;241m=\u001b[39m evaluate(model, loader, criterion, device, weights\u001b[38;5;241m=\u001b[39mloss_weights)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m acc_label=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_label\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m acc_variety=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_variety\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_weights' is not defined"
     ]
    }
   ],
   "source": [
    "def eval(loader=test_loader):\n",
    "    run_loss, correct_label, correct_variety, mae_age = evaluate(model, loader, criterion, device, weights=loss_weights)\n",
    "    print(f\"loss={run_loss:.4f} acc_label={correct_label:.3f} acc_variety={correct_variety:.3f}\")\n",
    "\n",
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b06063",
   "metadata": {},
   "source": [
    "### (Optional) Fine-tune the whole network\n",
    "\n",
    "After warming up the head, unfreeze the backbone and fine-tune at a **smaller LR**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d487979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 0.5808 acc 0.830 | valid loss 0.2047 acc 0.944\n",
      "Epoch 02 | train loss 0.3086 acc 0.903 | valid loss 0.2058 acc 0.938\n",
      "Epoch 03 | train loss 0.2780 acc 0.910 | valid loss 0.1629 acc 0.944\n",
      "Epoch 04 | train loss 0.2528 acc 0.920 | valid loss 0.1442 acc 0.960\n",
      "Epoch 05 | train loss 0.2260 acc 0.927 | valid loss 0.1297 acc 0.963\n",
      "Epoch 06 | train loss 0.2108 acc 0.933 | valid loss 0.1045 acc 0.963\n",
      "Epoch 07 | train loss 0.2107 acc 0.932 | valid loss 0.1270 acc 0.955\n",
      "Epoch 08 | train loss 0.2040 acc 0.933 | valid loss 0.1180 acc 0.967\n",
      "Epoch 09 | train loss 0.1927 acc 0.936 | valid loss 0.1487 acc 0.956\n",
      "Epoch 10 | train loss 0.1924 acc 0.937 | valid loss 0.1237 acc 0.962\n",
      "Epoch 11 | train loss 0.1682 acc 0.943 | valid loss 0.1370 acc 0.957\n",
      "Epoch 12 | train loss 0.1796 acc 0.945 | valid loss 0.1145 acc 0.970\n",
      "Epoch 13 | train loss 0.1631 acc 0.949 | valid loss 0.1247 acc 0.963\n",
      "Epoch 14 | train loss 0.1561 acc 0.949 | valid loss 0.1631 acc 0.959\n",
      "Epoch 15 | train loss 0.1569 acc 0.949 | valid loss 0.1329 acc 0.964\n",
      "Epoch 16 | train loss 0.1397 acc 0.956 | valid loss 0.1051 acc 0.970\n",
      "Epoch 17 | train loss 0.1375 acc 0.955 | valid loss 0.1127 acc 0.970\n",
      "Epoch 18 | train loss 0.1331 acc 0.957 | valid loss 0.1116 acc 0.969\n",
      "Epoch 19 | train loss 0.1291 acc 0.957 | valid loss 0.1305 acc 0.969\n",
      "Epoch 20 | train loss 0.1305 acc 0.958 | valid loss 0.1215 acc 0.968\n"
     ]
    }
   ],
   "source": [
    "# train the whole thing (unfreeze all layers)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "#make lr smaller for fine-tuning\n",
    "lr1=lr/10\n",
    "\n",
    "#reinitialize optimizer so we can train all parameters\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr1)\n",
    "\n",
    "train_and_evaluate(model, train_loader, valid_loader, optimizer, criterion, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433be9f",
   "metadata": {},
   "source": [
    "## 7) Save / Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to kaggle_paddy_timm_multihead.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_977419/3246647191.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('kaggle_paddy_timm_multihead.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'kaggle_paddy_timm_multihead.pth')\n",
    "print('Saved to kaggle_paddy_timm_multihead.pth')\n",
    "model.load_state_dict(torch.load('kaggle_paddy_timm_multihead.pth', map_location=device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b291e5f",
   "metadata": {},
   "source": [
    "## 8) Evaluation & Confusion Matrix\n",
    "\n",
    "Evaluate the model on the test_loader.  This is the **only** time the model sees this loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4605dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (6x6 for PaddyDoctor):\n",
      "[[ 54   0   0   2   0   0   0   0   0   1]\n",
      " [  0  44   0   0   0   0   0   0   0   0]\n",
      " [  0   0  39   0   0   0   0   0   0   0]\n",
      " [  0   0   0 159   0   0   3   1   0   1]\n",
      " [  0   1   0   1  94   0   3   0   0   0]\n",
      " [  0   0   2   0   0 141   0   0   0   0]\n",
      " [  0   0   0   5   0   0  60   0   0   2]\n",
      " [  0   0   0   2   0   0   1 139   2   1]\n",
      " [  0   0   0   0   0   0   0   4 169   1]\n",
      " [  0   0   0   2   1   0   1   3   0 101]]\n",
      "\n",
      "Per-class (precision, recall, f1):\n",
      "bacterial_leaf_blight: P=1.000 R=0.947 F1=0.973\n",
      "bacterial_leaf_streak: P=0.978 R=1.000 F1=0.989\n",
      "bacterial_panicle_blight: P=0.951 R=1.000 F1=0.975\n",
      "     blast: P=0.930 R=0.970 F1=0.949\n",
      "brown_spot: P=0.989 R=0.949 F1=0.969\n",
      "dead_heart: P=1.000 R=0.986 F1=0.993\n",
      "downy_mildew: P=0.882 R=0.896 F1=0.889\n",
      "     hispa: P=0.946 R=0.959 F1=0.952\n",
      "    normal: P=0.988 R=0.971 F1=0.980\n",
      "    tungro: P=0.944 R=0.935 F1=0.940\n",
      "\n",
      "Macro avg: P=0.961 R=0.961 F1=0.961\n",
      "Overall Accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "LOADER=test_loader\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_all_preds_targets(model, loader):\n",
    "    model.eval()\n",
    "    preds, targs = [], []\n",
    "    for images, variety_idx, age_norm, label_idx in loader:\n",
    "        images      = images.to(device)\n",
    "        variety_idx = variety_idx.to(device)\n",
    "        age_norm    = age_norm.to(device)\n",
    "        label_idx   = label_idx.to(device)\n",
    "\n",
    "        logits = model((images, variety_idx, age_norm))\n",
    "\n",
    "        #just want the label preds\n",
    "        preds.append(logits.argmax(1).cpu().numpy())\n",
    "        targs.append(label_idx.cpu().numpy())\n",
    "    return np.concatenate(preds), np.concatenate(targs)\n",
    "\n",
    "preds, targs = get_all_preds_targets(model, LOADER)\n",
    "\n",
    "# Confusion matrix\n",
    "num_classes = len(class_names)\n",
    "cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "for t, p in zip(targs, preds):\n",
    "    cm[t, p] += 1\n",
    "\n",
    "print('Confusion Matrix (6x6 for PaddyDoctor):')\n",
    "print(cm)\n",
    "\n",
    "# Per-class metrics\n",
    "per_class = []\n",
    "for k in range(num_classes):\n",
    "    TP = cm[k,k]\n",
    "    FP = cm[:,k].sum() - TP\n",
    "    FN = cm[k,:].sum() - TP\n",
    "    TN = cm.sum() - TP - FP - FN\n",
    "    prec = TP/(TP+FP) if (TP+FP)>0 else 0.0\n",
    "    rec  = TP/(TP+FN) if (TP+FN)>0 else 0.0\n",
    "    f1   = (2*prec*rec)/(prec+rec) if (prec+rec)>0 else 0.0\n",
    "    per_class.append((prec, rec, f1))\n",
    "\n",
    "macro_p = float(np.mean([p for p,_,_ in per_class]))\n",
    "macro_r = float(np.mean([r for _,r,_ in per_class]))\n",
    "macro_f = float(np.mean([f for _,_,f in per_class]))\n",
    "overall_acc = float((preds == targs).mean())\n",
    "\n",
    "print('\\nPer-class (precision, recall, f1):')\n",
    "for name,(p,r,f) in zip(class_names, per_class):\n",
    "    print(f'{name:>10s}: P={p:.3f} R={r:.3f} F1={f:.3f}')\n",
    "print(f\"\\nMacro avg: P={macro_p:.3f} R={macro_r:.3f} F1={macro_f:.3f}\")\n",
    "print(f'Overall Accuracy: {overall_acc:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
