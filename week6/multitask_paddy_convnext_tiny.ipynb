{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f23687",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸŒ¾ Multiâ€‘Head CNN with **timm** on Kaggle Paddy Dataset (`convnext_tiny`)\n",
    "\n",
    "This notebook demonstrates a **multiâ€‘task** setup using **PyTorch** and **timm** for the Kaggle **Paddy** dataset.\n",
    "\n",
    "We will:  \n",
    "1) Set up the environment and choose a timm backbone (`convnext_tiny`).  \n",
    "2) Build a **custom Dataset** reading `train.csv` (`image_id`, `label`, `variety`, `age`).  \n",
    "   - Images are stored in subfolders named by **label** (e.g., `train/<label>/<image_id>`).  \n",
    "   - Each sample returns a tuple: **`(image_tensor, variety_idx, age_float, label_idx)`** as requested.  \n",
    "3) Create DataLoaders with timmâ€‘compatible transforms.  \n",
    "4) Define a **multiâ€‘head model**:  \n",
    "   - Head A â†’ **disease label** classification  \n",
    "   - Head B â†’ **variety** classification  \n",
    "   - Head R â†’ **age** regression  \n",
    "5) Train and evaluate with a minimal, wellâ€‘commented loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac93656",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db7e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Missing data/train.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m TRAIN_CSV \u001b[38;5;241m=\u001b[39m DATA_ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m TRAIN_IMG_ROOT \u001b[38;5;241m=\u001b[39m DATA_ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m TRAIN_CSV\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRAIN_CSV\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m TRAIN_IMG_ROOT\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRAIN_IMG_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (folder of label subdirs)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Missing data/train.csv"
     ]
    }
   ],
   "source": [
    "\n",
    "# If needed:\n",
    "# !pip install -q timm pandas\n",
    "\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "DATA_ROOT = Path(\"./data/\") \n",
    "TRAIN_CSV = DATA_ROOT / 'train.csv'\n",
    "TRAIN_IMG_ROOT = DATA_ROOT / 'train'\n",
    "assert TRAIN_CSV.exists(), f\"Missing {TRAIN_CSV}\"\n",
    "assert TRAIN_IMG_ROOT.exists(), f\"Missing {TRAIN_IMG_ROOT} (folder of label subdirs)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a854e",
   "metadata": {},
   "source": [
    "## 2) Custom Dataset (returns `(image, variety, age, label)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PaddyMultitaskDataset(Dataset):\n",
    "    def __init__(self, csv_path: Path, img_root: Path, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        expected_cols = {'image_id', 'label', 'variety', 'age'}\n",
    "        missing = expected_cols - set(self.df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"CSV is missing columns: {missing}\")\n",
    "        self.img_root = Path(img_root)\n",
    "        self.transform = transform\n",
    "        self.labels = sorted(self.df['label'].astype(str).unique())\n",
    "        self.varieties = sorted(self.df['variety'].astype(str).unique())\n",
    "        self.label_to_idx = {s:i for i,s in enumerate(self.labels)}\n",
    "        self.variety_to_idx = {s:i for i,s in enumerate(self.varieties)}\n",
    "        self.df['age'] = pd.to_numeric(self.df['age'], errors='coerce')\n",
    "        if self.df['age'].isna().any():\n",
    "            med = float(self.df['age'].median())\n",
    "            self.df['age'] = self.df['age'].fillna(med)\n",
    "        self.num_label_classes = len(self.labels)\n",
    "        self.num_variety_classes = len(self.varieties)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = str(row['image_id'])\n",
    "        label_name = str(row['label'])\n",
    "        variety_name = str(row['variety'])\n",
    "        age_val = float(row['age'])\n",
    "\n",
    "        img_path = self.img_root / label_name / image_id\n",
    "        if not img_path.exists():\n",
    "            for ext in ('.jpg', '.jpeg', '.png', '.bmp'):\n",
    "                cand = img_path.with_suffix(ext)\n",
    "                if cand.exists():\n",
    "                    img_path = cand\n",
    "                    break\n",
    "        if not img_path.exists():\n",
    "            raise FileNotFoundError(f\"Image not found for row {idx}: {img_path}\")\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        y_label = self.label_to_idx[label_name]\n",
    "        y_var = self.variety_to_idx[variety_name]\n",
    "        y_age = age_val\n",
    "\n",
    "        return img, torch.tensor(y_var, dtype=torch.long), torch.tensor(y_age, dtype=torch.float32), torch.tensor(y_label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9d4f8",
   "metadata": {},
   "source": [
    "## 3) Transforms (timm) & Train/Valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15377864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = 'convnext_tiny'\n",
    "cfg = timm.data.resolve_data_config({}, model=MODEL_NAME)\n",
    "train_tfms = timm.data.create_transform(**cfg, is_training=True, hflip=0.5, auto_augment=None)\n",
    "valid_tfms = timm.data.create_transform(**cfg, is_training=False)\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "indices = np.arange(len(df)); np.random.shuffle(indices)\n",
    "val_frac = 0.1; n_val = max(1, int(len(indices) * val_frac))\n",
    "val_idx = indices[:n_val]; train_idx = indices[n_val:]\n",
    "\n",
    "train_csv_tmp = DATA_ROOT / 'train_split.csv'\n",
    "val_csv_tmp   = DATA_ROOT / 'valid_split.csv'\n",
    "df.iloc[train_idx].to_csv(train_csv_tmp, index=False)\n",
    "df.iloc[val_idx].to_csv(val_csv_tmp,   index=False)\n",
    "\n",
    "train_ds = PaddyMultitaskDataset(train_csv_tmp, TRAIN_IMG_ROOT, transform=train_tfms)\n",
    "valid_ds = PaddyMultitaskDataset(val_csv_tmp,   TRAIN_IMG_ROOT, transform=valid_tfms)\n",
    "\n",
    "print('Label classes:', train_ds.labels)\n",
    "print('Variety classes:', train_ds.varieties)\n",
    "print('Train/Valid sizes:', len(train_ds), len(valid_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b99da0",
   "metadata": {},
   "source": [
    "## 4) DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9923214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "xb, y_var, y_age, y_lbl = next(iter(train_loader))\n",
    "print('Batch shapes:', xb.shape, y_var.shape, y_age.shape, y_lbl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471cbec",
   "metadata": {},
   "source": [
    "## 5) Multiâ€‘head model (`convnext_tiny` backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da802c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadNet(nn.Module):\n",
    "    def __init__(self, model_name: str, num_label_classes: int, num_variety_classes: int, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.head_label   = nn.Linear(feat_dim, num_label_classes)\n",
    "        self.head_variety = nn.Linear(feat_dim, num_variety_classes)\n",
    "        self.head_age     = nn.Linear(feat_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        logits_label   = self.head_label(feats)\n",
    "        logits_variety = self.head_variety(feats)\n",
    "        age_pred       = self.head_age(feats).squeeze(1)\n",
    "        return {'label': logits_label, 'variety': logits_variety, 'age': age_pred}\n",
    "\n",
    "model = MultiHeadNet(MODEL_NAME, train_ds.num_label_classes, train_ds.num_variety_classes, pretrained=True).to(device)\n",
    "\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "print('Trainable params (heads only):', sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06dad23",
   "metadata": {},
   "source": [
    "## 6) Loss functions & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1908d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criteria = {\n",
    "    'label':   nn.CrossEntropyLoss(),\n",
    "    'variety': nn.CrossEntropyLoss(),\n",
    "    'age':     nn.SmoothL1Loss(beta=1.0)\n",
    "}\n",
    "loss_weights = {'label': 1.0, 'variety': 0.7, 'age': 0.5}\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8e0b0",
   "metadata": {},
   "source": [
    "## 7) Training / evaluation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef11abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_multitask_loss(outputs, targets, criteria, weights=None):\n",
    "    total = 0.0\n",
    "    for k in ['label', 'variety', 'age']:\n",
    "        w = 1.0 if (weights is None or k not in weights) else weights[k]\n",
    "        total = total + w * criteria[k](outputs[k], targets[k])\n",
    "    return total\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criteria, device, weights=None):\n",
    "    model.train()\n",
    "    run_loss, n = 0.0, 0\n",
    "    correct_label, correct_variety, total = 0, 0, 0\n",
    "    for images, y_var, y_age, y_lbl in loader:\n",
    "        images = images.to(device); y_lbl = y_lbl.to(device); y_var = y_var.to(device); y_age = y_age.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(images)\n",
    "        loss = compute_multitask_loss(outputs, {'label': y_lbl, 'variety': y_var, 'age': y_age}, criteria, weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bs = images.size(0)\n",
    "        run_loss += loss.item() * bs; n += bs; total += bs\n",
    "        correct_label   += (outputs['label'].argmax(1) == y_lbl).sum().item()\n",
    "        correct_variety += (outputs['variety'].argmax(1) == y_var).sum().item()\n",
    "    return run_loss / n, correct_label / total, correct_variety / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criteria, device, weights=None):\n",
    "    model.eval()\n",
    "    run_loss, n = 0.0, 0\n",
    "    correct_label, correct_variety, total, mae_age = 0, 0, 0, 0.0\n",
    "    for images, y_var, y_age, y_lbl in loader:\n",
    "        images = images.to(device); y_lbl = y_lbl.to(device); y_var = y_var.to(device); y_age = y_age.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = compute_multitask_loss(outputs, {'label': y_lbl, 'variety': y_var, 'age': y_age}, criteria, weights)\n",
    "        bs = images.size(0)\n",
    "        run_loss += loss.item() * bs; n += bs; total += bs\n",
    "        correct_label   += (outputs['label'].argmax(1) == y_lbl).sum().item()\n",
    "        correct_variety += (outputs['variety'].argmax(1) == y_var).sum().item()\n",
    "        mae_age         += torch.abs(outputs['age'] - y_age).sum().item()\n",
    "    return run_loss / n, correct_label / total, correct_variety / total, mae_age / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396407f",
   "metadata": {},
   "source": [
    "## 8) Train & validate (warmâ€‘up on heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 3\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc_lbl, tr_acc_var = train_one_epoch(model, train_loader, optimizer, criteria, device, weights=loss_weights)\n",
    "    va_loss, va_acc_lbl, va_acc_var, va_mae_age = evaluate(model, valid_loader, criteria, device, weights=loss_weights)\n",
    "    print(f\"epoch {ep:02d} | train loss {tr_loss:.4f} | val loss {va_loss:.4f} | \"\n",
    "          f\"label acc {va_acc_lbl:.3f} | variety acc {va_acc_var:.3f} | age MAE {va_mae_age:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf6b25",
   "metadata": {},
   "source": [
    "## 9) (Optional) Unfreeze & fineâ€‘tune the backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f83a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for p in model.backbone.parameters():\n",
    "    p.requires_grad = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "EPOCHS_FT = 2\n",
    "for ep in range(1, EPOCHS_FT + 1):\n",
    "    tr_loss, tr_acc_lbl, tr_acc_var = train_one_epoch(model, train_loader, optimizer, criteria, device, weights=loss_weights)\n",
    "    va_loss, va_acc_lbl, va_acc_var, va_mae_age = evaluate(model, valid_loader, criteria, device, weights=loss_weights)\n",
    "    print(f\"[FT] epoch {ep:02d} | train loss {tr_loss:.4f} | val loss {va_loss:.4f} | \"\n",
    "          f\"label acc {va_acc_lbl:.3f} | variety acc {va_acc_var:.3f} | age MAE {va_mae_age:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a35c2",
   "metadata": {},
   "source": [
    "## 10) Save / Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'multitask_convnext_tiny_paddy.pth')\n",
    "print('Saved to multitask_convnext_tiny_paddy.pth')\n",
    "# model.load_state_dict(torch.load('multitask_convnext_tiny_paddy.pth', map_location=device))\n",
    "# model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
