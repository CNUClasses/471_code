{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4ee8af",
   "metadata": {},
   "source": [
    "\n",
    "# Bi‑Encoder Retrieval vs Cross‑Encoder Re‑Ranking — Why Re‑Rankers Are Often More Accurate\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/CNUClasses/CPSC471/master/content/lectures/week12/cross_and_biencoder.png\" alt=\"standard\" >\n",
    "</p>\n",
    "<!-- Bi-Encoders produce for a given sentence a sentence embedding. \n",
    "**Training**: A bi-encoder (dual-encoder) uses two weight-tied transformers to map queries and passages into the same embedding space. It’s trained on (query, positive, negative) pairs with a contrastive loss so positives score higher than negatives, often using in-batch and hard negatives(queryies that are close in vector space but not correct).\n",
    "**Inference** Sentence embeddings are computed by pulling the embedding from u. \n",
    "\n",
    "Cross-Encoder, two sentences are passed simultaneously to the Transformer network. It produces an output value between 0 and 1 indicating the similarity of the input sentence pair: -->\n",
    "\n",
    "1) **Bi‑encoder** → fast candidate generation (dense vector search).  \n",
    "2) **Cross‑encoder (re‑ranker)** → accurate reordering of those candidates.\n",
    "\n",
    "> TL;DR: The **bi‑encoder** gives you *speed and scale*. The **re‑ranker** gives you *fine‑grained accuracy*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e508a3",
   "metadata": {},
   "source": [
    "\n",
    "## Why is a re‑ranker more accurate than a bi‑encoder? \n",
    "\n",
    "| Model | Input/Scoring | Strengths | Weaknesses |\n",
    "|---|---|---|---|\n",
    "| **Bi‑encoder** | Encodes **query** and **doc** *independently* into vectors; score = cosine/dot | Very **fast**, **scalable** (precompute doc vectors; index with FAISS/Chroma/Pinecone) | **No token‑level interaction** between query & doc; can miss subtle meaning (negation, entities, context) |\n",
    "| **Cross‑encoder** (Re‑ranker) | Reads **query + doc together** (e.g., `[CLS] query [SEP] doc`); predicts **relevance** | **Deep token‑level attention**; **context‑sensitive** scoring; higher **accuracy** | **Slower** (must score each pair), no doc precomputation |\n",
    "\n",
    "**Example:**\n",
    "\n",
    "**Query:** “Documents not about CNNs”\n",
    "\n",
    "**Doc:** “This paper discusses convolutional networks”\n",
    "\n",
    "- Bi-encoder: high similarity (misses “not”)\n",
    "\n",
    "- Re-ranker: low relevance (understands negation)\n",
    "\n",
    "\n",
    "**Reason the re‑ranker wins:** It attends across tokens of query **and** document jointly, so it can model negation, long‑distance dependencies, and nuanced phrasing that a single fixed vector (bi‑encoder output) cannot fully capture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477a2c1",
   "metadata": {},
   "source": [
    "\n",
    "## Typical RAG Retrieval Flow (two‑stage)\n",
    "\n",
    "```\n",
    "Query  ──► Bi‑encoder vector ──► ANN index (top‑k docs)\n",
    "                               └─► k candidates\n",
    "Query + each candidate doc ──► Cross‑encoder (re‑ranker) ──► final ordered list\n",
    "Top‑m chunks ──► Prompt context for LLM\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7ad12",
   "metadata": {},
   "source": [
    "\n",
    "## Setup (optional)\n",
    "If running on a fresh environment, uncomment and execute the cell below to install dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b092677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install -U sentence-transformers --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5d672",
   "metadata": {},
   "source": [
    "\n",
    "## Tiny Teaching Corpus and Queries\n",
    "We keep a small synthetic corpus and a few queries with \"gold\" doc ids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028f25f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    (\"d1\", \"Transformers use attention to model relationships between tokens in a sequence.\"),\n",
    "    (\"d2\", \"Convolutional neural networks are widely used in computer vision for image classification.\"),\n",
    "    (\"d3\", \"Retrieval-Augmented Generation (RAG) adds external knowledge via retrieval to improve LLM answers.\"),\n",
    "    (\"d4\", \"FAISS supports IVF and HNSW indexes for fast approximate nearest neighbor search at scale.\"),\n",
    "    (\"d5\", \"MiniLM and DistilBERT produce compact sentence embeddings suitable for dense retrieval.\"),\n",
    "    (\"d6\", \"BM25 is a keyword-based sparse retrieval method that relies on exact and partial token matches.\"),\n",
    "    (\"d7\", \"Cross-encoders score a query and a document together, enabling fine-grained token-level interactions.\"),\n",
    "    (\"d8\", \"Bi-encoders encode queries and documents independently, enabling fast vector search at scale.\")\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    (\"How can RAG improve answers from language models?\", \"d3\"),\n",
    "    (\"Which ANN index is graph-based and very fast?\", \"d4\"),\n",
    "    (\"Which small models are good for sentence embeddings?\", \"d5\"),\n",
    "    (\"What retrieval method uses keyword matches?\", \"d6\"),\n",
    "    (\"Why are cross-encoders often more accurate than bi-encoders?\", \"d7\"),\n",
    "]\n",
    "len(corpus), len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49758f9c",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 1 — Bi‑Encoder Retrieval (fast candidate generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9850ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "bi_encoder_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "bi_encoder = SentenceTransformer(bi_encoder_name)\n",
    "\n",
    "doc_ids   = [d for d,_ in corpus]\n",
    "doc_texts = [t for _,t in corpus]\n",
    "doc_embs  = bi_encoder.encode(doc_texts, normalize_embeddings=True, show_progress_bar=False)\n",
    "\n",
    "def bi_encoder_search(query: str, k: int = 5):\n",
    "    qv = bi_encoder.encode([query], normalize_embeddings=True, show_progress_bar=False)[0]\n",
    "    sims = doc_embs @ qv  # cosine similarity (normalized vectors)\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return idx, sims[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d6689",
   "metadata": {},
   "source": [
    "\n",
    "### Quick smoke test (bi‑encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cf300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d7',\n",
       "  0.5529755353927612,\n",
       "  'Cross-encoders score a query and a document together, enabling fine-grained token-level interactions.'),\n",
       " ('d8',\n",
       "  0.44767284393310547,\n",
       "  'Bi-encoders encode queries and documents independently, enabling fast vector search at scale.'),\n",
       " ('d3',\n",
       "  0.2939690351486206,\n",
       "  'Retrieval-Augmented Generation (RAG) adds external knowledge via retrieval to improve LLM answers.'),\n",
       " ('d1',\n",
       "  0.27219441533088684,\n",
       "  'Transformers use attention to model relationships between tokens in a sequence.'),\n",
       " ('d2',\n",
       "  0.22715233266353607,\n",
       "  'Convolutional neural networks are widely used in computer vision for image classification.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_query = \"What is a cross-encoder and why is it useful?\"\n",
    "cand_idx, cand_scores = bi_encoder_search(test_query, k=5)\n",
    "[(doc_ids[i], float(cand_scores[j]), doc_texts[i]) for j, i in enumerate(cand_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ced24",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 2 — Cross‑Encoder Re‑Ranking (accurate rescoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7bdcc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "cross_encoder = CrossEncoder(cross_encoder_name)\n",
    "\n",
    "def cross_encoder_rerank(query: str, candidate_indices):\n",
    "    pairs = [(query, doc_texts[i]) for i in candidate_indices]\n",
    "    scores = cross_encoder.predict(pairs)  # higher = more relevant\n",
    "    order = np.argsort(-scores)\n",
    "    return [(candidate_indices[i], float(scores[i])) for i in order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6030ec",
   "metadata": {},
   "source": [
    "\n",
    "### Quick smoke test (cross‑encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d21bd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d7',\n",
       "  5.196783542633057,\n",
       "  'Cross-encoders score a query and a document together, enabling fine-grained token-level interactions.'),\n",
       " ('d8',\n",
       "  -1.3642516136169434,\n",
       "  'Bi-encoders encode queries and documents independently, enabling fast vector search at scale.'),\n",
       " ('d2',\n",
       "  -9.761394500732422,\n",
       "  'Convolutional neural networks are widely used in computer vision for image classification.'),\n",
       " ('d3',\n",
       "  -10.232885360717773,\n",
       "  'Retrieval-Augmented Generation (RAG) adds external knowledge via retrieval to improve LLM answers.'),\n",
       " ('d1',\n",
       "  -10.348474502563477,\n",
       "  'Transformers use attention to model relationships between tokens in a sequence.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reranked = cross_encoder_rerank(test_query, cand_idx.tolist())\n",
    "[(doc_ids[i], score, doc_texts[i]) for i, score in reranked]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1284f60",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation — Precision@k and MRR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4129eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision_at_k(ranked_doc_ids, gold_id, k=5):\n",
    "    return 1.0 if gold_id in ranked_doc_ids[:k] else 0.0\n",
    "\n",
    "def reciprocal_rank(ranked_doc_ids, gold_id):\n",
    "    for rank, did in enumerate(ranked_doc_ids, start=1):\n",
    "        if did == gold_id:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e24a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P@3': (1.0, 1.0),\n",
       " 'MRR': (0.9, 1.0),\n",
       " 'Avg Time (ms)': (5.287599563598633, 5.764532089233398)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import time, numpy as np\n",
    "\n",
    "def evaluate_pipeline(queries, k_candidates=5, k_eval=3):\n",
    "    bi_precisions, rer_precisions = [], []\n",
    "    bi_mrrs, rer_mrrs = [], []\n",
    "    bi_times, rer_times = [], []\n",
    "\n",
    "    for qtext, gold in queries:\n",
    "        t0 = time.time()\n",
    "        cand_idx, _ = bi_encoder_search(qtext, k=k_candidates)\n",
    "        bi_times.append(time.time() - t0)\n",
    "        bi_ranked = [doc_ids[i] for i in cand_idx]\n",
    "\n",
    "        t1 = time.time()\n",
    "        reranked = cross_encoder_rerank(qtext, cand_idx.tolist())\n",
    "        rer_times.append(time.time() - t1)\n",
    "        rer_ranked = [doc_ids[i] for i,_ in reranked]\n",
    "\n",
    "        bi_precisions.append(precision_at_k(bi_ranked, gold, k_eval))\n",
    "        rer_precisions.append(precision_at_k(rer_ranked, gold, k_eval))\n",
    "        bi_mrrs.append(reciprocal_rank(bi_ranked, gold))\n",
    "        rer_mrrs.append(reciprocal_rank(rer_ranked, gold))\n",
    "\n",
    "    return {\n",
    "        f\"P@{k_eval}\": (float(np.mean(bi_precisions)), float(np.mean(rer_precisions))),\n",
    "        \"MRR\": (float(np.mean(bi_mrrs)), float(np.mean(rer_mrrs))),\n",
    "        \"Avg Time (ms)\": (float(np.mean(bi_times)*1000), float(np.mean(rer_times)*1000))\n",
    "    }\n",
    "\n",
    "results = evaluate_pipeline(queries, k_candidates=5, k_eval=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c40b4e",
   "metadata": {},
   "source": [
    "\n",
    "## Visualizing Rank Shifts (before vs after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a330e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: Why use a re-ranker with dense retrieval?\n",
      "\n",
      "Bi-encoder top-k:  ['d5', 'd6', 'd8', 'd3', 'd4']\n",
      "Re-ranker top-k:   ['d5', 'd6', 'd3', 'd8', 'd4']\n",
      "\n",
      "Bi-encoder texts:\n",
      " - d5: MiniLM and DistilBERT produce compact sentence embeddings suitable for dense retrieval.\n",
      " - d6: BM25 is a keyword-based sparse retrieval method that relies on exact and partial token matches.\n",
      " - d8: Bi-encoders encode queries and documents independently, enabling fast vector search at scale.\n",
      " - d3: Retrieval-Augmented Generation (RAG) adds external knowledge via retrieval to improve LLM answers.\n",
      " - d4: FAISS supports IVF and HNSW indexes for fast approximate nearest neighbor search at scale.\n",
      "\n",
      "Re-ranker texts:\n",
      " - d5: MiniLM and DistilBERT produce compact sentence embeddings suitable for dense retrieval.\n",
      " - d6: BM25 is a keyword-based sparse retrieval method that relies on exact and partial token matches.\n",
      " - d3: Retrieval-Augmented Generation (RAG) adds external knowledge via retrieval to improve LLM answers.\n",
      " - d8: Bi-encoders encode queries and documents independently, enabling fast vector search at scale.\n",
      " - d4: FAISS supports IVF and HNSW indexes for fast approximate nearest neighbor search at scale.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_rank_shift(query: str, k_candidates=5):\n",
    "    cand_idx, _ = bi_encoder_search(query, k=k_candidates)\n",
    "    bi_ranked = [doc_ids[i] for i in cand_idx]\n",
    "    reranked = cross_encoder_rerank(query, cand_idx.tolist())\n",
    "    rer_ranked = [doc_ids[i] for i,_ in reranked]\n",
    "\n",
    "    print(f\"QUERY: {query}\\n\")\n",
    "    print(\"Bi-encoder top-k: \", bi_ranked)\n",
    "    print(\"Re-ranker top-k:  \", rer_ranked)\n",
    "    print(\"\\nBi-encoder texts:\")\n",
    "    for did in bi_ranked:\n",
    "        print(f\" - {did}: {doc_texts[doc_ids.index(did)]}\")\n",
    "    print(\"\\nRe-ranker texts:\")\n",
    "    for did in rer_ranked:\n",
    "        print(f\" - {did}: {doc_texts[doc_ids.index(did)]}\")\n",
    "\n",
    "show_rank_shift(\"Why use a re-ranker with dense retrieval?\", k_candidates=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9720e2",
   "metadata": {},
   "source": [
    "\n",
    "## Summary & Exercises\n",
    "\n",
    "**Summary**\n",
    "- **Bi‑encoder**: fast/scalable candidate fetch, but limited by fixed-vector similarity.  \n",
    "- **Cross‑encoder**: slower, but more accurate via joint token‑level attention.  \n",
    "- **Best practice**: bi‑encoder → top‑k → cross‑encoder → top‑m to LLM.\n",
    "\n",
    "**Exercises**\n",
    "1. Scale the corpus to 100+ items (copy your notes) and re‑measure P@3/MRR and latency.  \n",
    "2. Try `k_candidates ∈ {5, 10, 20}` and plot P@3 vs re‑ranker time.  \n",
    "3. Swap bi‑encoder (`all‑MiniLM‑L6‑v2`) for `all‑mpnet‑base‑v2`; compare.  \n",
    "4. Index `doc_embs` with FAISS IVF/HNSW and measure retrieval latency vs brute force.  \n",
    "5. Add BM25 (sparse) and do **hybrid** (sparse+dense) before re‑ranking.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
