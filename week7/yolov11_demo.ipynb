{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4882e59a",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸš€ YOLOv11: Object Detection Demo (Install â†’ mAP/IoU â†’ Fineâ€‘tune â†’ License)\n",
    "\n",
    "This notebook introduces **YOLOv11** using the Ultralytics package. You'll:\n",
    "- Install and verify the `ultralytics` package (YOLO CLI + Python API).\n",
    "- Run a quick **inference** demo.\n",
    "- Understand **IoU** and **mAP** with small, concrete examples.\n",
    "- **Fineâ€‘tune** a YOLOv11 model on a toy dataset and evaluate.\n",
    "- Review **licensing** considerations for research vs. commercial use.\n",
    "\n",
    "> **Note:** Cells that download models/data require internet access in your environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d0039",
   "metadata": {},
   "source": [
    "## 0) Install Ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1baa0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall opencv-python -y\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59faa35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]\n",
      "PyTorch: 2.5.0+cu124\n",
      "Ultralytics: 8.3.205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If not installed, uncomment the next line\n",
    "# !pip install -U ultralytics\n",
    "import sys, torch\n",
    "print('Python:', sys.version)\n",
    "print('PyTorch:', torch.__version__)\n",
    "\n",
    "try:\n",
    "    import ultralytics\n",
    "    from ultralytics import YOLO\n",
    "    print('Ultralytics:', ultralytics.__version__)\n",
    "except Exception as e:\n",
    "    print(\"Ultralytics not available yet. Run pip install above.\\n\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1285f2d",
   "metadata": {},
   "source": [
    "## 1) Quick Start: Pretrained Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65b619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/kperkins411/471_code/week7/bus.jpg: 640x480 4 persons, 1 bus, 36.4ms\n",
      "Speed: 6.6ms preprocess, 36.4ms inference, 62.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/kperkins411/471_code/week7/runs/detect/predict5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([5., 0., 0., 0., 0.], device='cuda:0')\n",
       "conf: tensor([0.9402, 0.8881, 0.8782, 0.8558, 0.6219], device='cuda:0')\n",
       "data: tensor([[3.8074e+00, 2.2936e+02, 7.9621e+02, 7.2842e+02, 9.4019e-01, 5.0000e+00],\n",
       "        [6.7102e+02, 3.9485e+02, 8.0981e+02, 8.7871e+02, 8.8812e-01, 0.0000e+00],\n",
       "        [4.7413e+01, 3.9957e+02, 2.3930e+02, 9.0420e+02, 8.7822e-01, 0.0000e+00],\n",
       "        [2.2306e+02, 4.0868e+02, 3.4447e+02, 8.6044e+02, 8.5577e-01, 0.0000e+00],\n",
       "        [2.1391e-02, 5.5607e+02, 6.8883e+01, 8.7236e+02, 6.2188e-01, 0.0000e+00]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (1080, 810)\n",
       "shape: torch.Size([5, 6])\n",
       "xywh: tensor([[400.0092, 478.8904, 792.4037, 499.0573],\n",
       "        [740.4153, 636.7804, 138.7878, 483.8646],\n",
       "        [143.3546, 651.8820, 191.8829, 504.6299],\n",
       "        [283.7636, 634.5623, 121.4106, 451.7573],\n",
       "        [ 34.4523, 714.2173,  68.8618, 316.2908]], device='cuda:0')\n",
       "xywhn: tensor([[0.4938, 0.4434, 0.9783, 0.4621],\n",
       "        [0.9141, 0.5896, 0.1713, 0.4480],\n",
       "        [0.1770, 0.6036, 0.2369, 0.4672],\n",
       "        [0.3503, 0.5876, 0.1499, 0.4183],\n",
       "        [0.0425, 0.6613, 0.0850, 0.2929]], device='cuda:0')\n",
       "xyxy: tensor([[3.8074e+00, 2.2936e+02, 7.9621e+02, 7.2842e+02],\n",
       "        [6.7102e+02, 3.9485e+02, 8.0981e+02, 8.7871e+02],\n",
       "        [4.7413e+01, 3.9957e+02, 2.3930e+02, 9.0420e+02],\n",
       "        [2.2306e+02, 4.0868e+02, 3.4447e+02, 8.6044e+02],\n",
       "        [2.1391e-02, 5.5607e+02, 6.8883e+01, 8.7236e+02]], device='cuda:0')\n",
       "xyxyn: tensor([[4.7005e-03, 2.1237e-01, 9.8298e-01, 6.7446e-01],\n",
       "        [8.2842e-01, 3.6560e-01, 9.9976e-01, 8.1362e-01],\n",
       "        [5.8535e-02, 3.6997e-01, 2.9543e-01, 8.3722e-01],\n",
       "        [2.7538e-01, 3.7841e-01, 4.2527e-01, 7.9670e-01],\n",
       "        [2.6409e-05, 5.1488e-01, 8.5041e-02, 8.0774e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL = 'yolo11n.pt'  # or 'yolo11s.pt'\n",
    "model = YOLO(MODEL)\n",
    "\n",
    "# Predict on a sample image (downloads on first run)\n",
    "# pred = model.predict(source='https://ultralytics.com/images/bus.jpg', save=True, imgsz=640)\n",
    "pred = model.predict(source='./bus.jpg', save=True, imgsz=640)\n",
    "pred[0].boxes[:5] if len(pred) else print(\"No result\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7f8c8",
   "metadata": {},
   "source": [
    "## 2) Metrics: IoU and mAP (What they mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f9bf2",
   "metadata": {},
   "source": [
    "\n",
    "**Intersection over Union (IoU)** measures how well a predicted box overlaps a groundâ€‘truth box:\n",
    "\\[ \\text{IoU} = \\frac{\\text{Area}(\\text{Pred} \\cap \\text{GT})}{\\text{Area}(\\text{Pred} \\cup \\text{GT})} \\]\n",
    "- IoU âˆˆ [0, 1]. Higher is better; an IoU of 0.5 is common as a positive match threshold.\n",
    "\n",
    "**Average Precision (AP)** summarizes the **precisionâ€“recall** curve for one class at a given IoU threshold.\n",
    "\n",
    "**mAP** is the **mean AP across classes**, sometimes averaged across multiple IoU thresholds:\n",
    "- **mAP@0.5** (VOC style)\n",
    "- **mAP@0.5:0.95** (COCO style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a3b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81, 0.032, 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Simple IoU demo for axis-aligned boxes (x1, y1, x2, y2)\n",
    "def box_iou(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)\n",
    "    inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)\n",
    "    inter_w = max(0.0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0.0, inter_y2 - inter_y1)\n",
    "    inter = inter_w * inter_h\n",
    "    area_a = (ax2 - ax1) * (ay2 - ay1)\n",
    "    area_b = (bx2 - bx1) * (by2 - by1)\n",
    "    union = area_a + area_b - inter\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "gt = (10, 10, 50, 50)\n",
    "preds = [(12, 12, 48, 48), (40, 40, 80, 80), (60, 60, 90, 90)]\n",
    "[round(box_iou(gt, p), 3) for p in preds]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5226d9",
   "metadata": {},
   "source": [
    "## 3) Evaluate on a small dataset (COCO128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt')\n",
    "metrics = model.val(data='coco128.yaml', imgsz=640)  # downloads tiny dataset\n",
    "metrics.box.map, metrics.box.map50, metrics.box.maps[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58383868",
   "metadata": {},
   "source": [
    "## 4) Fineâ€‘tuning YOLOv11 (custom data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424ad20",
   "metadata": {},
   "source": [
    "\n",
    "### YOLO data.yaml\n",
    "```yaml\n",
    "path: /path/to/dataset\n",
    "train: images/train\n",
    "val:   images/val\n",
    "names:\n",
    "  0: classA\n",
    "  1: classB\n",
    "```\n",
    "\n",
    "### CLI\n",
    "```bash\n",
    "yolo detect train model=yolo11s.pt data=/path/to/data.yaml imgsz=640 epochs=50 batch=16 amp=True\n",
    "```\n",
    "\n",
    "### Python API\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11s.pt')\n",
    "results = model.train(data='/path/to/data.yaml', imgsz=640, epochs=50, batch=16, optimizer='AdamW', amp=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ad380",
   "metadata": {},
   "source": [
    "## 5) Licensing notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1284028",
   "metadata": {},
   "source": [
    "\n",
    "Ultralytics YOLOv11 is distributed under **AGPLâ€‘3.0** by default. For **commercial distribution** (shipping products or services),\n",
    "either comply with AGPLâ€‘3.0 obligations or obtain a **commercial license** from Ultralytics.\n",
    "\n",
    "Always check the latest terms on Ultralyticsâ€™ website before deployment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
