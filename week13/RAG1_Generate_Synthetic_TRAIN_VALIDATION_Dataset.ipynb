{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa5cdb1",
   "metadata": {},
   "source": [
    "\n",
    "# Generate a QA Evaluation Dataset from ChromaDB (10% sample) for RAG Testing\n",
    "<img src=\"https://raw.githubusercontent.com/CNUClasses/CPSC471/master/content/lectures/week13/generate_synthetic_dataset_no_heading.png\" alt=\"standard\" style=\"max-height:300px;  margin:10px 0; vertical-align:middle;\">\n",
    "\n",
    "**Goal:** Build an **evaluation dataset** for RAG by sampling **10%** of a **pre‑chunked ChromaDB** collection and generating up to **5 question–answer pairs per chunk** using **OpenAI** *or* a **Hugging Face** model. Save the result to **CSV**.\n",
    "\n",
    "### Why a relatively powerful LLM for question generation?\n",
    "- **Answerability & grounding:** It must read a chunk and ask **non‑trivial but answerable** questions grounded **only** in that chunk (no outside knowledge).  \n",
    "- **Paraphrase variety:** Better models generate diverse phrasings.  \n",
    "- **Domain nuance:** Strong models handle **technical jargon** and produce **faithful** answers rather than hallucinations.  But this may break down in specialized fields with unique vocabulary/phrasing such as law or medical.\n",
    "- **Format adherence:** Higher‑end models more reliably output **valid JSON** you can parse automatically.\n",
    "\n",
    "> This notebook keeps costs in check by sampling **10%** of chunks and capping to **≤5 Q/A per chunk**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da314073",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup & Installation\n",
    "\n",
    "Uncomment the cell below if you need to install dependencies.  \n",
    "We support **either** OpenAI **or** Hugging Face for question generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a638abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -U chromadb openai transformers accelerate torch pandas numpy tqdm python-dotenv\n",
    "# If you're on Apple Silicon:\n",
    "# !pip install 'torch>=2.2.0' --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e2bd0",
   "metadata": {},
   "source": [
    "\n",
    "### Configuration\n",
    "- **ChromaDB:** point to your persisted DB folder and collection name.  \n",
    "- **Sampling:** set `SAMPLE_FRACTION=0.10` (10%).  \n",
    "- **Generation choice:** set `USE_OPENAI=True` (needs `OPENAI_API_KEY`) or `USE_HF=True` (downloads HF model).  \n",
    "- **Safety knobs:** `MAX_Q_PER_CHUNK` (≤5), `MAX_CHARS_PER_CHUNK` to truncate very long chunks.\n",
    "\n",
    "> If both `USE_OPENAI` and `USE_HF` are True, OpenAI is used by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_device('cuda:1')\n",
    "\n",
    "# ---- User-editable parameters ----\n",
    "PERSIST_DIR = \"../week12/rag_chroma\"        # ChromaDB persistence path (folder will be created)\n",
    "# PERSIST_DIR = os.getenv(\"../week12\", \"./rag_chroma\")\n",
    "COLLECTION_NAME= \"cnu_rag_lab\"                       # collection name used previously\n",
    "# COLLECTION_NAME   = os.getenv(\"cnu_rag_lab\", \"my_chunks\")\n",
    "\n",
    "SAMPLE_FRACTION   = float(os.getenv(\"SAMPLE_FRACTION\", \"0.2\"))  # 20% of total chunks for train/valid/test\n",
    "VALID_FRACTION  = float(os.getenv(\"VALID_FRACTION\", \"0.5\"))   # 50% of SAMPLED chunks for validation\n",
    "# TEST_FRACTION   = float(os.getenv(\"TEST_FRACTION\", \"0.25\"))    # 25% of SAMPLED chunks for testing\n",
    "\n",
    "MAX_Q_PER_CHUNK   = int(os.getenv(\"MAX_Q_PER_CHUNK\", \"5\"))       # cap at 5\n",
    "MAX_CHARS_PER_CHUNK = int(os.getenv(\"MAX_CHARS_PER_CHUNK\", \"3000\")) #we cap out at 1532 I think so the chunk preview should be the entire chunk\n",
    "RANDOM_SEED       = int(os.getenv(\"RANDOM_SEED\", \"471\"))\n",
    "\n",
    "# Generation backends\n",
    "USE_OPENAI = os.getenv(\"USE_OPENAI\", \"False\").lower() == \"true\"\n",
    "USE_HF     = os.getenv(\"USE_HF\", \"True\").lower() == \"true\"  # default to HF to avoid API keys\n",
    "\n",
    "# OpenAI config\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # set in env or .env\n",
    "\n",
    "# Hugging Face config (choose a small instruct model if running on CPU)\n",
    "HF_TASK  = \"text2text-generation\"  # for instruction-style prompting\n",
    "HF_MODEL = os.getenv(\"HF_MODEL\", \"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "# HF_MODEL = os.getenv(\"HF_MODEL\", \"google/flan-t5-base\")  # lightweight; upgrade if you have GPU\n",
    "\n",
    "HF_MAX_NEW_TOKENS = int(os.getenv(\"HF_MAX_NEW_TOKENS\", \"512\"))\n",
    "HF_DO_SAMPLE = os.getenv(\"HF_DO_SAMPLE\", \"False\").lower() == \"true\"\n",
    "\n",
    "# Output\n",
    "VALID_CSV = os.getenv(\"VALID_CSV\", \"rag_eval_dataset.csv\")\n",
    "TRAIN_CSV = os.getenv(\"TRAIN_CSV\", \"rag_train_dataset.csv\")\n",
    "\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ed370",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Connect to ChromaDB and load chunks\n",
    "\n",
    "We assume your data is **already chunked** and stored in a Chroma collection.  \n",
    "We’ll read IDs, documents, and metadatas in **pages** to avoid loading everything at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6add652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks in collection 'cnu_rag_lab': 1256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=PERSIST_DIR)\n",
    "collection = client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "total = collection.count()\n",
    "print(f\"Total chunks in collection '{COLLECTION_NAME}': {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe9bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1256 items from Chroma.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Retrieve all ids, docs, and metadatas with paging ----\n",
    "ALL_IDS, ALL_DOCS, ALL_META = [], [], []\n",
    "\n",
    "PAGE = 1000\n",
    "offset = 0\n",
    "while True:\n",
    "    batch = collection.get(\n",
    "        include=[\"documents\", \"metadatas\"],\n",
    "        limit=PAGE,\n",
    "        offset=offset\n",
    "    )\n",
    "    ids = batch.get(\"ids\", [])\n",
    "    docs = batch.get(\"documents\", [])\n",
    "    metas = batch.get(\"metadatas\", [])\n",
    "    if not ids:\n",
    "        break\n",
    "    ALL_IDS.extend(ids)\n",
    "    ALL_DOCS.extend(docs)\n",
    "    ALL_META.extend(metas)\n",
    "    offset += len(ids)\n",
    "    if offset >= total:\n",
    "        break\n",
    "\n",
    "print(f\"Loaded {len(ALL_IDS)} items from Chroma.\")\n",
    "assert len(ALL_IDS) == len(ALL_DOCS) == len(ALL_META)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f50bf218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ALL_DOCS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb2366",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Sample ~20% of chunks (reproducible)\n",
    "\n",
    "We take a 20% sample to keep cost/time manageable. You can adjust `SAMPLE_FRACTION`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dfa34e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 251 / 1256 chunks (~20.0%).\n",
      "Prepared 251 chunks for question generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# total number of chunks available (based on loaded ALL_IDS)\n",
    "n_total = len(ALL_IDS)\n",
    "\n",
    "# number to sample: SAMPLE_FRACTION of total, but at least 1 to avoid empty samples\n",
    "n_sample = max(1, int(n_total * SAMPLE_FRACTION))\n",
    "\n",
    "# create a list of indices corresponding to chunk positions\n",
    "indices = list(range(n_total))\n",
    "\n",
    "# shuffle indices in-place to get a random sample (random.seed set earlier for reproducibility)\n",
    "random.shuffle(indices)\n",
    "\n",
    "# take the first n_sample shuffled indices and sort them so sampled chunks are in ascending order\n",
    "sample_idx = sorted(indices[:n_sample])\n",
    "\n",
    "print(f\"Sampling {n_sample} / {n_total} chunks (~{SAMPLE_FRACTION*100:.1f}%).\")\n",
    "\n",
    "SAMPLED = [\n",
    "    {\n",
    "        \"chunk_id\": ALL_IDS[i],\n",
    "        \"text\": (ALL_DOCS[i] or \"\")[:MAX_CHARS_PER_CHUNK],  # truncate long chunks\n",
    "        \"metadata\": ALL_META[i] or {}\n",
    "    }\n",
    "    for i in sample_idx\n",
    "]\n",
    "print(f\"Prepared {len(SAMPLED)} chunks for question generation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721120f0",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Prompt design for grounded Q/A\n",
    "\n",
    "We ask the model to produce **up to 5 Q/A pairs** that are **fully answerable from the chunk** and return **valid JSON**:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\"question\": \"...\", \"answer\": \"...\"},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "If the chunk lacks enough information, the model should return **[]**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0991a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JSON_INSTRUCTIONS = (\n",
    "    \"Return ONLY a JSON array of objects, each with keys 'question' and 'answer'. \"\n",
    "    \"Do not include any extra commentary. If the chunk lacks enough info, return [].\"\n",
    ")\n",
    "\n",
    "def build_prompt(chunk_text: str, max_q: int) -> str:\n",
    "    return (\n",
    "        \"You are a careful question writer for Retrieval-Augmented Generation (RAG).\\n\"\n",
    "        \"Read the CHUNK below and create up to {max_q} question–answer pairs that are:\\n\"\n",
    "        \" - Non-trivial but fully answerable using ONLY the CHUNK\\n\"\n",
    "        \" - If you think there may be other chunks with relevant information, only create questions that can be answered using this CHUNK alone.\\n\"\n",
    "        \" - Concise, precise, and faithful to the CHUNK (no outside knowledge)\\n\"\n",
    "        \" - Useful for evaluating a retriever's ability to find this CHUNK\\n\\n\"\n",
    "        f\"{JSON_INSTRUCTIONS}\\n\\n\"\n",
    "        \"CHUNK:\\n\"\n",
    "        f\"{chunk_text}\\n\\n\"\n",
    "        \"JSON:\"\n",
    "    ).format(max_q=max_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6beb6362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are a careful question writer for Retrieval-Augmented Generation (RAG).\\n'\n",
      " 'Read the CHUNK below and create up to 3 question–answer pairs that are:\\n'\n",
      " ' - Non-trivial but fully answerable using ONLY the CHUNK\\n'\n",
      " ' - If you think there may be other chunks with relevant information, only '\n",
      " 'create questions that can be answered using this CHUNK alone.\\n'\n",
      " ' - Concise, precise, and faithful to the CHUNK (no outside knowledge)\\n'\n",
      " \" - Useful for evaluating a retriever's ability to find this CHUNK\\n\"\n",
      " '\\n'\n",
      " \"Return ONLY a JSON array of objects, each with keys 'question' and 'answer'. \"\n",
      " 'Do not include any extra commentary. If the chunk lacks enough info, return '\n",
      " '[].\\n'\n",
      " '\\n'\n",
      " 'CHUNK:\\n'\n",
      " '***SAMPLE CHUNK***\\n'\n",
      " '\\n'\n",
      " 'JSON:')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pprint import PrettyPrinter\n",
    "# Create a PrettyPrinter with custom indentation\n",
    "pp = PrettyPrinter(indent=4)\n",
    "pp.pprint(build_prompt(\"***SAMPLE CHUNK***\", 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c10a8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Choose a generation backend\n",
    "\n",
    "Set **`USE_OPENAI=True`** to call OpenAI Chat Completions; otherwise we default to a **Hugging Face** model (`text2text-generation`).  \n",
    "For CPU‑only environments, start with `google/flan-t5-base` (lower quality, but free). On GPU, try a stronger instruct model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9446030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- OpenAI backend (chat completions) ----\n",
    "def openai_generate_json(prompt: str) -> str:\n",
    "    \"\"\"Return raw JSON string from OpenAI Chat Completions.\"\"\"\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":\"You write grounded Q/A pairs in strict JSON.\"},\n",
    "                {\"role\":\"user\",\"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return resp.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"OpenAI generation failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c1c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Hugging Face backend (text2text-generation) ----\n",
    "from transformers import pipeline\n",
    "\n",
    "_hf_pipe = None\n",
    "def hf_generate_json(prompt: str) -> str:\n",
    "    global _hf_pipe\n",
    "    if _hf_pipe is None:\n",
    "        _hf_pipe = pipeline(HF_TASK, model=HF_MODEL)\n",
    "    out = _hf_pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=HF_MAX_NEW_TOKENS,\n",
    "        do_sample=HF_DO_SAMPLE\n",
    "    )\n",
    "    # HF pipelines return a list of dicts; try the first item\n",
    "    text = out[0].get(\"generated_text\", \"\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b2df3",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Robust JSON parsing of model output\n",
    "\n",
    "Models sometimes wrap JSON in prose or code fences. We defensively extract the first JSON array.\n",
    "If parsing fails, we fall back to a very simple regex that looks for `\"question\"` and `\"answer\"` pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b265f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def extract_json_array(text: str) -> List[Dict[str, Any]]:\n",
    "    # Try to find a JSON array block\n",
    "    # 1) Inline code fence\n",
    "    fence = re.findall(r\"```(?:json)?\\s*(\\[.*?\\])\\s*```\", text, flags=re.S)\n",
    "    candidates = fence if fence else re.findall(r\"(\\[\\s*{.*?}\\s*\\])\", text, flags=re.S)\n",
    "    if candidates:\n",
    "        raw = candidates[0]\n",
    "    else:\n",
    "        raw = text.strip()\n",
    "    try:\n",
    "        arr = json.loads(raw)\n",
    "        if isinstance(arr, list):\n",
    "            # sanitize items\n",
    "            clean = []\n",
    "            for it in arr:\n",
    "                if isinstance(it, dict) and 'question' in it and 'answer' in it:\n",
    "                    q = str(it['question']).strip()\n",
    "                    a = str(it['answer']).strip()\n",
    "                    if q and a:\n",
    "                        clean.append({'question': q, 'answer': a})\n",
    "            return clean\n",
    "        return []\n",
    "    except Exception:\n",
    "        # Fallback: scrape \"question\":\"...\", \"answer\":\"...\" naive pairs\n",
    "        pairs = []\n",
    "        pattern = re.findall(r'\"question\"\\s*:\\s*\"(.*?)\"\\s*,\\s*\"answer\"\\s*:\\s*\"(.*?)\"', text, flags=re.S)\n",
    "        for q,a in pattern:\n",
    "            q = q.strip().replace('\\n',' ')\n",
    "            a = a.strip().replace('\\n',' ')\n",
    "            if q and a:\n",
    "                pairs.append({'question': q, 'answer': a})\n",
    "        return pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68aa8ac",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Generate Q/A pairs for the sampled chunks\n",
    "\n",
    "We iterate over the sample, build a grounded prompt, call the selected backend, parse JSON,\n",
    "and collect **up to 5 Q/A** per chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16846e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Q/A:   0%|          | 0/251 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a629fe2b479481cb6dbc8b6785de340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n",
      "The model 'MistralForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'VoxtralForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   0%|          | 1/251 [00:21<1:29:54, 21.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   1%|          | 2/251 [00:32<1:04:15, 15.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   1%|          | 3/251 [00:44<56:40, 13.71s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   2%|▏         | 4/251 [00:55<52:50, 12.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   2%|▏         | 5/251 [01:07<50:45, 12.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   2%|▏         | 6/251 [01:17<47:39, 11.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   3%|▎         | 7/251 [01:29<47:26, 11.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   3%|▎         | 8/251 [01:50<58:53, 14.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   4%|▎         | 9/251 [02:04<58:27, 14.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   4%|▍         | 10/251 [02:16<54:51, 13.66s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   4%|▍         | 11/251 [02:26<50:30, 12.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   5%|▍         | 12/251 [02:41<52:41, 13.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   5%|▌         | 13/251 [02:55<53:38, 13.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   6%|▌         | 14/251 [03:08<53:19, 13.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   6%|▌         | 15/251 [03:20<51:21, 13.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   6%|▋         | 16/251 [03:33<51:07, 13.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   7%|▋         | 17/251 [03:53<58:17, 14.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   7%|▋         | 18/251 [04:05<54:52, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   8%|▊         | 19/251 [04:14<49:13, 12.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   8%|▊         | 20/251 [04:29<50:37, 13.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   8%|▊         | 21/251 [04:44<53:15, 13.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   9%|▉         | 22/251 [04:58<53:09, 13.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:   9%|▉         | 23/251 [05:10<50:06, 13.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  10%|▉         | 24/251 [05:24<51:28, 13.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  10%|▉         | 25/251 [05:36<49:08, 13.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  10%|█         | 26/251 [05:53<53:00, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  11%|█         | 27/251 [06:06<51:36, 13.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  11%|█         | 28/251 [06:18<49:10, 13.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  12%|█▏        | 29/251 [06:33<51:08, 13.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  12%|█▏        | 30/251 [06:51<55:25, 15.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  12%|█▏        | 31/251 [07:04<53:08, 14.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  13%|█▎        | 32/251 [07:24<58:51, 16.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  13%|█▎        | 33/251 [07:36<54:30, 15.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  14%|█▎        | 34/251 [07:48<50:30, 13.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  14%|█▍        | 35/251 [08:00<48:05, 13.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  14%|█▍        | 36/251 [08:13<47:47, 13.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  15%|█▍        | 37/251 [08:27<48:38, 13.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  15%|█▌        | 38/251 [08:43<50:36, 14.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  16%|█▌        | 39/251 [08:52<44:20, 12.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  16%|█▌        | 40/251 [09:05<45:23, 12.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  16%|█▋        | 41/251 [09:23<50:07, 14.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  17%|█▋        | 42/251 [09:39<51:09, 14.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  17%|█▋        | 43/251 [09:52<49:13, 14.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  18%|█▊        | 44/251 [10:07<50:15, 14.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  18%|█▊        | 45/251 [10:19<47:01, 13.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  18%|█▊        | 46/251 [10:29<43:43, 12.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  19%|█▊        | 47/251 [10:45<46:43, 13.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  19%|█▉        | 48/251 [10:59<46:40, 13.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  20%|█▉        | 49/251 [11:10<43:00, 12.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  20%|█▉        | 50/251 [11:25<45:20, 13.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  20%|██        | 51/251 [11:38<44:09, 13.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  21%|██        | 52/251 [11:47<40:01, 12.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  21%|██        | 53/251 [12:03<43:28, 13.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  22%|██▏       | 54/251 [12:20<47:49, 14.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  22%|██▏       | 55/251 [12:37<49:06, 15.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  22%|██▏       | 56/251 [12:52<49:00, 15.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  23%|██▎       | 57/251 [13:04<46:22, 14.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  23%|██▎       | 58/251 [13:20<47:09, 14.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  24%|██▎       | 59/251 [13:34<46:21, 14.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  24%|██▍       | 60/251 [13:54<51:21, 16.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  24%|██▍       | 61/251 [14:06<47:15, 14.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  25%|██▍       | 62/251 [14:26<51:56, 16.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  25%|██▌       | 63/251 [14:41<50:08, 16.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  25%|██▌       | 64/251 [14:58<51:09, 16.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  26%|██▌       | 65/251 [15:19<54:32, 17.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  26%|██▋       | 66/251 [15:35<53:25, 17.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  27%|██▋       | 67/251 [15:49<49:51, 16.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  27%|██▋       | 68/251 [16:05<48:47, 16.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  27%|██▋       | 69/251 [16:20<47:49, 15.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  28%|██▊       | 70/251 [16:40<51:40, 17.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  28%|██▊       | 71/251 [16:52<47:05, 15.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  29%|██▊       | 72/251 [17:08<46:30, 15.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  29%|██▉       | 73/251 [17:18<41:13, 13.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  29%|██▉       | 74/251 [17:29<38:40, 13.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  30%|██▉       | 75/251 [17:47<43:12, 14.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  30%|███       | 76/251 [18:04<44:07, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  31%|███       | 77/251 [18:14<40:01, 13.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  31%|███       | 78/251 [18:26<37:54, 13.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  31%|███▏      | 79/251 [18:42<40:34, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  32%|███▏      | 80/251 [18:51<35:56, 12.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  32%|███▏      | 81/251 [19:05<36:54, 13.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  33%|███▎      | 82/251 [19:25<42:32, 15.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  33%|███▎      | 83/251 [19:41<42:28, 15.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  33%|███▎      | 84/251 [19:56<42:35, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  34%|███▍      | 85/251 [20:09<40:26, 14.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  34%|███▍      | 86/251 [20:20<36:56, 13.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  35%|███▍      | 87/251 [20:36<38:29, 14.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  35%|███▌      | 88/251 [20:50<38:29, 14.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  35%|███▌      | 89/251 [21:06<39:49, 14.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  36%|███▌      | 90/251 [21:19<38:20, 14.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  36%|███▋      | 91/251 [21:30<35:01, 13.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  37%|███▋      | 92/251 [21:40<32:38, 12.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  37%|███▋      | 93/251 [21:54<33:32, 12.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  37%|███▋      | 94/251 [22:06<32:37, 12.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  38%|███▊      | 95/251 [22:20<34:10, 13.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  38%|███▊      | 96/251 [22:32<32:49, 12.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  39%|███▊      | 97/251 [22:52<38:06, 14.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  39%|███▉      | 98/251 [23:03<34:56, 13.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  39%|███▉      | 99/251 [23:13<32:16, 12.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  40%|███▉      | 100/251 [23:31<36:03, 14.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  40%|████      | 101/251 [23:51<40:05, 16.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  41%|████      | 102/251 [24:11<42:47, 17.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  41%|████      | 103/251 [24:28<41:50, 16.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  41%|████▏     | 104/251 [24:39<37:11, 15.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  42%|████▏     | 105/251 [24:58<40:03, 16.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  42%|████▏     | 106/251 [25:13<38:14, 15.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  43%|████▎     | 107/251 [25:33<40:55, 17.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  43%|████▎     | 108/251 [25:47<38:50, 16.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  43%|████▎     | 109/251 [26:07<41:06, 17.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  44%|████▍     | 110/251 [26:19<37:00, 15.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  44%|████▍     | 111/251 [26:34<36:28, 15.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  45%|████▍     | 112/251 [26:51<37:09, 16.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  45%|████▌     | 113/251 [27:11<39:46, 17.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  45%|████▌     | 114/251 [27:32<41:36, 18.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  46%|████▌     | 115/251 [27:52<42:44, 18.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  46%|████▌     | 116/251 [28:04<37:37, 16.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  47%|████▋     | 117/251 [28:15<33:28, 14.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  47%|████▋     | 118/251 [28:29<32:34, 14.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  47%|████▋     | 119/251 [28:43<31:38, 14.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  48%|████▊     | 120/251 [29:02<34:35, 15.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  48%|████▊     | 121/251 [29:15<32:49, 15.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  49%|████▊     | 122/251 [29:30<31:59, 14.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  49%|████▉     | 123/251 [29:47<33:06, 15.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  49%|████▉     | 124/251 [30:04<33:48, 15.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  50%|████▉     | 125/251 [30:23<35:43, 17.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  50%|█████     | 126/251 [30:43<37:29, 18.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  51%|█████     | 127/251 [31:03<38:04, 18.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  51%|█████     | 128/251 [31:15<34:07, 16.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  51%|█████▏    | 129/251 [31:26<30:15, 14.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  52%|█████▏    | 130/251 [31:38<28:02, 13.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  52%|█████▏    | 131/251 [31:54<29:12, 14.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  53%|█████▎    | 132/251 [32:09<29:06, 14.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  53%|█████▎    | 133/251 [32:24<29:06, 14.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  53%|█████▎    | 134/251 [32:38<28:15, 14.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  54%|█████▍    | 135/251 [32:52<27:48, 14.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  54%|█████▍    | 136/251 [33:02<25:25, 13.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  55%|█████▍    | 137/251 [33:15<24:41, 12.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  55%|█████▍    | 138/251 [33:29<25:12, 13.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  55%|█████▌    | 139/251 [33:40<23:51, 12.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  56%|█████▌    | 140/251 [33:55<24:26, 13.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  56%|█████▌    | 141/251 [34:11<25:46, 14.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  57%|█████▋    | 142/251 [34:25<25:27, 14.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  57%|█████▋    | 143/251 [34:41<26:42, 14.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  57%|█████▋    | 144/251 [34:54<25:11, 14.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  58%|█████▊    | 145/251 [35:08<25:13, 14.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  58%|█████▊    | 146/251 [35:28<27:55, 15.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  59%|█████▊    | 147/251 [35:41<25:49, 14.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  59%|█████▉    | 148/251 [35:54<24:54, 14.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  59%|█████▉    | 149/251 [36:07<23:28, 13.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  60%|█████▉    | 150/251 [36:20<22:52, 13.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  60%|██████    | 151/251 [36:37<24:35, 14.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  61%|██████    | 152/251 [36:51<24:05, 14.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  61%|██████    | 153/251 [37:04<23:04, 14.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  61%|██████▏   | 154/251 [37:17<22:17, 13.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  62%|██████▏   | 155/251 [37:27<20:12, 12.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  62%|██████▏   | 156/251 [37:41<20:23, 12.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  63%|██████▎   | 157/251 [38:01<23:35, 15.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  63%|██████▎   | 158/251 [38:21<25:38, 16.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  63%|██████▎   | 159/251 [38:35<24:16, 15.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  64%|██████▎   | 160/251 [38:48<22:41, 14.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  64%|██████▍   | 161/251 [39:04<22:46, 15.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  65%|██████▍   | 162/251 [39:16<21:17, 14.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  65%|██████▍   | 163/251 [39:32<21:47, 14.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  65%|██████▌   | 164/251 [39:46<21:16, 14.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  66%|██████▌   | 165/251 [40:07<23:24, 16.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  66%|██████▌   | 166/251 [40:20<21:51, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  67%|██████▋   | 167/251 [40:40<23:39, 16.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  67%|██████▋   | 168/251 [40:52<21:26, 15.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  67%|██████▋   | 169/251 [41:13<23:05, 16.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  68%|██████▊   | 170/251 [41:24<20:23, 15.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  68%|██████▊   | 171/251 [41:37<19:24, 14.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  69%|██████▊   | 172/251 [41:57<21:13, 16.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  69%|██████▉   | 173/251 [42:11<20:22, 15.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  69%|██████▉   | 174/251 [42:30<21:16, 16.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  70%|██████▉   | 175/251 [42:44<20:13, 15.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  70%|███████   | 176/251 [43:01<20:10, 16.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  71%|███████   | 177/251 [43:16<19:35, 15.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  71%|███████   | 178/251 [43:29<18:00, 14.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  71%|███████▏  | 179/251 [43:44<18:03, 15.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  72%|███████▏  | 180/251 [43:59<17:35, 14.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  72%|███████▏  | 181/251 [44:10<15:58, 13.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  73%|███████▎  | 182/251 [44:30<17:57, 15.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  73%|███████▎  | 183/251 [44:40<15:44, 13.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  73%|███████▎  | 184/251 [44:54<15:36, 13.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  74%|███████▎  | 185/251 [45:07<15:10, 13.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  74%|███████▍  | 186/251 [45:21<15:05, 13.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  75%|███████▍  | 187/251 [45:35<14:46, 13.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  75%|███████▍  | 188/251 [45:48<14:10, 13.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  75%|███████▌  | 189/251 [46:02<14:09, 13.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  76%|███████▌  | 190/251 [46:16<14:10, 13.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  76%|███████▌  | 191/251 [46:31<14:08, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  76%|███████▋  | 192/251 [46:51<15:34, 15.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  77%|███████▋  | 193/251 [47:12<16:55, 17.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  77%|███████▋  | 194/251 [47:26<15:37, 16.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  78%|███████▊  | 195/251 [47:36<13:37, 14.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  78%|███████▊  | 196/251 [47:55<14:30, 15.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  78%|███████▊  | 197/251 [48:09<13:38, 15.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  79%|███████▉  | 198/251 [48:25<13:38, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  79%|███████▉  | 199/251 [48:39<13:05, 15.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  80%|███████▉  | 200/251 [48:54<12:43, 14.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  80%|████████  | 201/251 [49:06<11:41, 14.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  80%|████████  | 202/251 [49:26<12:55, 15.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  81%|████████  | 203/251 [49:42<12:47, 15.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  81%|████████▏ | 204/251 [49:56<12:02, 15.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  82%|████████▏ | 205/251 [50:05<10:20, 13.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  82%|████████▏ | 206/251 [50:18<09:54, 13.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  82%|████████▏ | 207/251 [50:34<10:22, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  83%|████████▎ | 208/251 [50:43<09:07, 12.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  83%|████████▎ | 209/251 [50:52<08:01, 11.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  84%|████████▎ | 210/251 [51:05<08:15, 12.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  84%|████████▍ | 211/251 [51:21<08:45, 13.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  84%|████████▍ | 212/251 [51:33<08:15, 12.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  85%|████████▍ | 213/251 [51:48<08:27, 13.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  85%|████████▌ | 214/251 [52:05<09:00, 14.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  86%|████████▌ | 215/251 [52:21<08:55, 14.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  86%|████████▌ | 216/251 [52:33<08:16, 14.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  86%|████████▋ | 217/251 [52:44<07:24, 13.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  87%|████████▋ | 218/251 [53:00<07:44, 14.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  87%|████████▋ | 219/251 [53:18<08:02, 15.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  88%|████████▊ | 220/251 [53:29<07:16, 14.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  88%|████████▊ | 221/251 [53:40<06:29, 12.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  88%|████████▊ | 222/251 [53:56<06:46, 14.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  89%|████████▉ | 223/251 [54:06<05:57, 12.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  89%|████████▉ | 224/251 [54:21<06:01, 13.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  90%|████████▉ | 225/251 [54:38<06:14, 14.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  90%|█████████ | 226/251 [54:49<05:39, 13.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  90%|█████████ | 227/251 [55:04<05:35, 13.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  91%|█████████ | 228/251 [55:15<04:59, 13.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  91%|█████████ | 229/251 [55:26<04:30, 12.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  92%|█████████▏| 230/251 [55:40<04:29, 12.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  92%|█████████▏| 231/251 [55:54<04:24, 13.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  92%|█████████▏| 232/251 [56:08<04:16, 13.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  93%|█████████▎| 233/251 [56:21<03:58, 13.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  93%|█████████▎| 234/251 [56:34<03:45, 13.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  94%|█████████▎| 235/251 [56:45<03:22, 12.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  94%|█████████▍| 236/251 [57:00<03:21, 13.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  94%|█████████▍| 237/251 [57:17<03:22, 14.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  95%|█████████▍| 238/251 [57:31<03:03, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  95%|█████████▌| 239/251 [57:41<02:36, 13.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  96%|█████████▌| 240/251 [57:51<02:11, 11.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  96%|█████████▌| 241/251 [58:00<01:50, 11.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  96%|█████████▋| 242/251 [58:09<01:34, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  97%|█████████▋| 243/251 [58:17<01:19,  9.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  97%|█████████▋| 244/251 [58:27<01:07,  9.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  98%|█████████▊| 245/251 [58:36<00:58,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  98%|█████████▊| 246/251 [58:45<00:47,  9.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  98%|█████████▊| 247/251 [58:54<00:37,  9.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  99%|█████████▉| 248/251 [59:07<00:30, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A:  99%|█████████▉| 249/251 [59:15<00:19,  9.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A: 100%|█████████▉| 250/251 [59:30<00:11, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Generating Q/A: 100%|██████████| 251/251 [59:40<00:00, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1223 Q/A rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "backend = \"openai\" if USE_OPENAI else \"hf\"\n",
    "print(f\"Using backend: {backend}\")\n",
    "\n",
    "rows = []\n",
    "for item in tqdm(SAMPLED, desc=\"Generating Q/A\"):\n",
    "    chunk_id = item[\"chunk_id\"]\n",
    "    text = item[\"text\"] or \"\"\n",
    "    meta = item[\"metadata\"] or {}\n",
    "\n",
    "    if not text.strip():\n",
    "        continue\n",
    "\n",
    "    prompt = build_prompt(text, MAX_Q_PER_CHUNK)\n",
    "    try:\n",
    "        if USE_OPENAI:  # prefer OpenAI if explicitly enabled\n",
    "            raw = openai_generate_json(prompt)\n",
    "        else:\n",
    "            raw = hf_generate_json(prompt)\n",
    "        qa_list = extract_json_array(raw)[:MAX_Q_PER_CHUNK]\n",
    "    except Exception as e:\n",
    "        qa_list = []\n",
    "        print(f\"[WARN] Generation failed for chunk {chunk_id}: {e}\")\n",
    "\n",
    "    preview = text\n",
    "    source = meta.get(\"source\") or meta.get(\"file_path\") or meta.get(\"url\") or \"\"\n",
    "\n",
    "    for qa in qa_list:\n",
    "        rows.append({\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"question\": qa[\"question\"],\n",
    "            \"answer\": qa[\"answer\"],\n",
    "            \"source\": source,\n",
    "            \"metadata\": json.dumps(meta, ensure_ascii=False),\n",
    "            \"chunk\": preview\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"chunk_id\",\"question\",\"answer\",\"source\",\"metadata\",\"chunk\"])\n",
    "print(f\"Generated {len(df)} Q/A rows.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a61475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What days of the week are campus tours offered...</td>\n",
       "      <td>Come See for Yourself \\nReady to picture your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Which minor subjects are offered under the cat...</td>\n",
       "      <td>Health Studies ..................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Which minors require 143 credits?</td>\n",
       "      <td>Film Studies, minor .............................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Which minor fields of study are offered in the...</td>\n",
       "      <td>Philosophy of Law, minor ........................</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "5   What days of the week are campus tours offered...   \n",
       "15  Which minor subjects are offered under the cat...   \n",
       "20                  Which minors require 143 credits?   \n",
       "25  Which minor fields of study are offered in the...   \n",
       "\n",
       "                                                chunk  \n",
       "5   Come See for Yourself \\nReady to picture your ...  \n",
       "15  Health Studies ..................................  \n",
       "20  Film Studies, minor .............................  \n",
       "25  Philosophy of Law, minor ........................  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[5,15,20,25], ['question', 'chunk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee6ed29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>metadata</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>What is Christopher Newport University known for?</td>\n",
       "      <td>Christopher Newport University is known for it...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What are some opportunities for students at Ch...</td>\n",
       "      <td>Students at Christopher Newport University can...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What programs does Christopher Newport Univers...</td>\n",
       "      <td>Christopher Newport University offers the Pres...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>What is unique about the student body at Chris...</td>\n",
       "      <td>The student body at Christopher Newport Univer...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>What can students expect from their professors...</td>\n",
       "      <td>Students at Christopher Newport University can...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>What days of the week are campus tours offered...</td>\n",
       "      <td>Campus tours are offered Monday through Saturday.</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>Come See for Yourself \\nReady to picture your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>How can one schedule a visit to Christopher Ne...</td>\n",
       "      <td>One can schedule a visit online at admission.c...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>Come See for Yourself \\nReady to picture your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>What is the phone number to call for schedulin...</td>\n",
       "      <td>(757) 594-7015/(800) 333-4268</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>Come See for Yourself \\nReady to picture your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Is it possible to schedule a campus tour on ma...</td>\n",
       "      <td>No, campus tours are not offered on major holi...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>Come See for Yourself \\nReady to picture your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>What is the website to visit for scheduling a ...</td>\n",
       "      <td>admission.cnu.edu</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>Come See for Yourself \\nReady to picture your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>According to the Christopher Newport Universit...</td>\n",
       "      <td>Intentional acts of lying, cheating or stealin...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>What is expected of all members of the Christo...</td>\n",
       "      <td>It is expected that all members of the univers...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Who is responsible for reporting violations of...</td>\n",
       "      <td>Members of this university community are oblig...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>What values does the Christopher Newport Unive...</td>\n",
       "      <td>The Christopher Newport University community c...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>What are the consequences of violating the Chr...</td>\n",
       "      <td>Violations of the Honor Code result in sanctio...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...</td>\n",
       "      <td>4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>Which minor subjects are offered under the cat...</td>\n",
       "      <td>The minor subjects offered under the category ...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>Health Studies ..................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>What is the catalog number for Museum Studies ...</td>\n",
       "      <td>Museum Studies is offered as a minor with the ...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>Health Studies ..................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Which minor subjects fall under the category '...</td>\n",
       "      <td>Interdisciplinary Studies is a minor subject w...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>Health Studies ..................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>What is the catalog number for Digital Humanit...</td>\n",
       "      <td>Digital Humanities is offered as a minor with ...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>Health Studies ..................................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>Which minor subjects are available for Film St...</td>\n",
       "      <td>Film Studies is offered as a minor with the ca...</td>\n",
       "      <td>./pdfs/2025-26-undergraduate_catalog.pdf</td>\n",
       "      <td>{\"source\": \"./pdfs/2025-26-undergraduate_catal...</td>\n",
       "      <td>Health Studies ..................................</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id                                           question  \\\n",
       "0         2  What is Christopher Newport University known for?   \n",
       "1         2  What are some opportunities for students at Ch...   \n",
       "2         2  What programs does Christopher Newport Univers...   \n",
       "3         2  What is unique about the student body at Chris...   \n",
       "4         2  What can students expect from their professors...   \n",
       "5         7  What days of the week are campus tours offered...   \n",
       "6         7  How can one schedule a visit to Christopher Ne...   \n",
       "7         7  What is the phone number to call for schedulin...   \n",
       "8         7  Is it possible to schedule a campus tour on ma...   \n",
       "9         7  What is the website to visit for scheduling a ...   \n",
       "10        8  According to the Christopher Newport Universit...   \n",
       "11        8  What is expected of all members of the Christo...   \n",
       "12        8  Who is responsible for reporting violations of...   \n",
       "13        8  What values does the Christopher Newport Unive...   \n",
       "14        8  What are the consequences of violating the Chr...   \n",
       "15       17  Which minor subjects are offered under the cat...   \n",
       "16       17  What is the catalog number for Museum Studies ...   \n",
       "17       17  Which minor subjects fall under the category '...   \n",
       "18       17  What is the catalog number for Digital Humanit...   \n",
       "19       17  Which minor subjects are available for Film St...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   Christopher Newport University is known for it...   \n",
       "1   Students at Christopher Newport University can...   \n",
       "2   Christopher Newport University offers the Pres...   \n",
       "3   The student body at Christopher Newport Univer...   \n",
       "4   Students at Christopher Newport University can...   \n",
       "5   Campus tours are offered Monday through Saturday.   \n",
       "6   One can schedule a visit online at admission.c...   \n",
       "7                       (757) 594-7015/(800) 333-4268   \n",
       "8   No, campus tours are not offered on major holi...   \n",
       "9                                   admission.cnu.edu   \n",
       "10  Intentional acts of lying, cheating or stealin...   \n",
       "11  It is expected that all members of the univers...   \n",
       "12  Members of this university community are oblig...   \n",
       "13  The Christopher Newport University community c...   \n",
       "14  Violations of the Honor Code result in sanctio...   \n",
       "15  The minor subjects offered under the category ...   \n",
       "16  Museum Studies is offered as a minor with the ...   \n",
       "17  Interdisciplinary Studies is a minor subject w...   \n",
       "18  Digital Humanities is offered as a minor with ...   \n",
       "19  Film Studies is offered as a minor with the ca...   \n",
       "\n",
       "                                      source  \\\n",
       "0   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "1   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "2   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "3   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "4   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "5   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "6   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "7   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "8   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "9   ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "10  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "11  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "12  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "13  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "14  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "15  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "16  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "17  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "18  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "19  ./pdfs/2025-26-undergraduate_catalog.pdf   \n",
       "\n",
       "                                             metadata  \\\n",
       "0   {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "1   {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "2   {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "3   {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "4   {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "5   {\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "6   {\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "7   {\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "8   {\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "9   {\"page\": 2, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "10  {\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "11  {\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "12  {\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "13  {\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "14  {\"page\": 3, \"source\": \"./pdfs/2025-26-undergra...   \n",
       "15  {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "16  {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "17  {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "18  {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "19  {\"source\": \"./pdfs/2025-26-undergraduate_catal...   \n",
       "\n",
       "                                                chunk  \n",
       "0   2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...  \n",
       "1   2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...  \n",
       "2   2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...  \n",
       "3   2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...  \n",
       "4   2 \\n      \\n  \\n   \\n \\n  \\n  \\n \\n \\n \\n \\n \\...  \n",
       "5   Come See for Yourself \\nReady to picture your ...  \n",
       "6   Come See for Yourself \\nReady to picture your ...  \n",
       "7   Come See for Yourself \\nReady to picture your ...  \n",
       "8   Come See for Yourself \\nReady to picture your ...  \n",
       "9   Come See for Yourself \\nReady to picture your ...  \n",
       "10  4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...  \n",
       "11  4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...  \n",
       "12  4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...  \n",
       "13  4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...  \n",
       "14  4 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n   \\n \\n ...  \n",
       "15  Health Studies ..................................  \n",
       "16  Health Studies ..................................  \n",
       "17  Health Studies ..................................  \n",
       "18  Health Studies ..................................  \n",
       "19  Health Studies ..................................  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edc7d749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What days of the week are campus tours offered at Christopher Newport '\n",
      " 'University?')\n",
      "'Campus tours are offered Monday through Saturday.'\n",
      "('Come See for Yourself \\n'\n",
      " 'Ready to picture your life as a CNU Captain? Schedule \\n'\n",
      " 'a visit and see why so many students choose to call Chris-\\n'\n",
      " 'topher Newport home. \\n'\n",
      " 'Campus tours are offered Monday through Saturday \\n'\n",
      " '(except major holidays). Visit us online at admission.cnu. \\n'\n",
      " 'edu or call (757) 594-7015/(800) 333-4268. \\n'\n",
      " 'We look forward to showing you why Christopher New-\\n'\n",
      " 'port is the number one regional public university in Virginia!')\n"
     ]
    }
   ],
   "source": [
    "from pprint import PrettyPrinter\n",
    "# Create a PrettyPrinter with custom indentation\n",
    "pp = PrettyPrinter(indent=4)\n",
    "\n",
    "df.head(5).iloc[:5,:3]\n",
    "pp.pprint(df.iloc[5,1])\n",
    "pp.pprint(df.iloc[5,2])\n",
    "pp.pprint(df.iloc[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ac2b095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count=1223, Min=239, Max=1535, Mean=1345.5, Median=1495.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = df['chunk'].str.len()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(lengths, bins=30, edgecolor='black')\n",
    "plt.title('chunk length distribution')\n",
    "plt.xlabel('Characters')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Count={len(lengths)}, Min={lengths.min()}, Max={lengths.max()}, Mean={lengths.mean():.1f}, Median={lengths.median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facacce",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Split into train and evaluation datasets and save to CSV\n",
    "\n",
    "This CSV can be loaded by your **RAG evaluation** notebook to compute **Recall@K, Precision@K, MAP, and MRR**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e2f306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 607 Q/A pairs from 125 unique chunks\n",
      "Valid set: 616 Q/A pairs from 126 unique chunks\n",
      "Overlap check: 0 chunks in both (should be 0)\n"
     ]
    }
   ],
   "source": [
    "# Split df into two equal parts, ensuring no duplicate chunk_ids in each\n",
    "# First, get unique chunk_ids and shuffle them\n",
    "unique_chunk_ids = df['chunk_id'].unique().tolist()\n",
    "random.shuffle(unique_chunk_ids)\n",
    "\n",
    "# Split chunk_ids into two equal parts\n",
    "split_point = len(unique_chunk_ids) // 2\n",
    "train_chunk_ids = unique_chunk_ids[:split_point]\n",
    "valid_chunk_ids = unique_chunk_ids[split_point:]\n",
    "\n",
    "# Create train and validation dataframes based on chunk_id splits\n",
    "train_df = df[df['chunk_id'].isin(train_chunk_ids)].copy()\n",
    "valid_df = df[df['chunk_id'].isin(valid_chunk_ids)].copy()\n",
    "\n",
    "print(f\"Train set: {len(train_df)} Q/A pairs from {len(train_chunk_ids)} unique chunks\")\n",
    "print(f\"Valid set: {len(valid_df)} Q/A pairs from {len(valid_chunk_ids)} unique chunks\")\n",
    "print(f\"Overlap check: {len(set(train_chunk_ids).intersection(set(valid_chunk_ids)))} chunks in both (should be 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f3c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap check: 0 chunks in both (should be 0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46f90319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training dataset to: rag_train_dataset.csv\n",
      "Saved evaluation dataset to: rag_eval_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_df.to_csv(TRAIN_CSV, index=False)\n",
    "print(f\"Saved training dataset to: {TRAIN_CSV}\")\n",
    "\n",
    "valid_df.to_csv(VALID_CSV, index=False)\n",
    "print(f\"Saved evaluation dataset to: {VALID_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "673f5048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2368\n",
      "drwxr-xr-x.  4 kperkins411 kperkins411    4096 Nov 19 13:45 .\n",
      "drwxr-xr-x. 16 kperkins411 kperkins411    4096 Nov 14 13:22 ..\n",
      "drwxr-xr-x.  2 kperkins411 kperkins411      28 Nov 14 17:37 chroma\n",
      "-rw-r--r--.  1 kperkins411 kperkins411  112025 Nov 19 14:04 Chroma_QA_Eval_Generator.ipynb\n",
      "drwxr-xr-x.  2 kperkins411 kperkins411      46 Nov 14 17:44 __pycache__\n",
      "-rw-r--r--.  1 kperkins411 kperkins411 1023893 Nov 19 14:04 rag_eval_dataset.csv\n",
      "-rw-r--r--.  1 kperkins411 kperkins411   69772 Nov 19 13:45 rag_eval_per_query_metrics.csv\n",
      "-rw-r--r--.  1 kperkins411 kperkins411   45875 Nov 19 13:45 RAG_Evaluate_with_rag_api.ipynb\n",
      "-rw-r--r--.  1 kperkins411 kperkins411   22484 Nov 17 13:23 RAG_Metrics_Practice_Notebook.ipynb\n",
      "-rw-r--r--.  1 kperkins411 kperkins411    7664 Nov 14 17:44 rag_pipeline_api.py\n",
      "-rw-r--r--.  1 kperkins411 kperkins411   74900 Nov 14 17:19 RAG_Retriever_Eval_with_BM25.ipynb\n",
      "-rw-r--r--.  1 kperkins411 kperkins411 1041530 Nov 19 14:04 rag_train_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90277448",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Tips & Next Steps\n",
    "\n",
    "- **Quality control:** Spot‑check a few rows to ensure questions are **answerable from the chunk** and answers are **faithful**.  \n",
    "- **Stronger models ⇒ better Q/A:** If using HF on CPU (e.g., `flan‑t5‑base`), consider upgrading to a stronger instruct model on GPU for higher‑quality questions.  \n",
    "- **De‑duplication:** Remove near‑duplicate questions across chunks to reduce evaluation bias.  \n",
    "- **Balance sampling:** You can stratify sampling by source/file/topic to ensure coverage.  \n",
    "- **Costs:** OpenAI usage scales with tokens; keep chunks truncated and sample fraction small to control spend.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
